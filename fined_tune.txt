{"messages": [{"role": "user", "content": "Founded by the creators of Ray, a framework for distributed computing. Easily build, deploy, and manage distributed applications with Anyscale. Run at any scale, from a laptop to a data center.. Learn more about Ray"}, {"role": "assistant", "content": "https://www.anyscale.com/about"}]}
{"messages": [{"role": "user", "content": "Build and develop distributed applications at any scale. With a serverless experience, Anyscale allows you to focus on your application instead of your infrastructure.. Sign up for the beta"}, {"role": "assistant", "content": "https://www.anyscale.com/product"}]}
{"messages": [{"role": "user", "content": ". Upcoming events"}, {"role": "assistant", "content": "https://www.anyscale.com/events"}]}
{"messages": [{"role": "user", "content": ". Past events"}, {"role": "assistant", "content": "https://www.anyscale.com/events/past"}]}
{"messages": [{"role": "user", "content": ". All Open Roles"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale"}]}
{"messages": [{"role": "user", "content": "Site Reliability Engineers (SREs) are responsible for keeping all user-facing services and other Anyscale production systems running smoothly. SREs are a blend of pragmatic operators and software craftspeople that apply sound engineering principles, operational discipline, and mature automation to our environments and the Anyscale codebase.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/f527683d-63fd-41b8-9dbd-84c2cdf9fd1a"}]}
{"messages": [{"role": "user", "content": "We are hiring strong software engineers for a variety of roles. Examples include:\n\n- Distributed systems engineering\n- Scalable machine learning libraries\n- Frontend engineering. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/3625823e-3654-403d-b8ed-6c2cf425e3ca"}]}
{"messages": [{"role": "user", "content": "Ray was created to make it easier to scale diverse computation tasks and distributed state across a cluster, with a minimum of distributed systems expertise and knowledge required. This crash course discusses the particular challenges Ray meets, how Ray works under the hood, how to use Ray in your own applications, and how to debug problems when they occur.\n\nMany users of Ray will actually use a higher-level, domain-specific libraries, rather than the core API. The other tutorials cover these libraries.. Watch the live event video"}, {"role": "assistant", "content": "https://youtu.be/2dgIEwkGYGI"}]}
{"messages": [{"role": "user", "content": "Ray RLlib is the Ray-based library for implementing reinforcement learning applications, supporting all the popular, state-of-the-art libraries, including integrations with TensorFlow and PyTorch for deep reinforcement learning. This tutorial explains RL principles and common algorithms, including multi-armed bandits, using a series of example problems.. Watch the live event video"}, {"role": "assistant", "content": "https://youtu.be/y2KjC7W9nsI"}]}
{"messages": [{"role": "user", "content": "This tutorial covers Ray Tune for hyperparameter tuning and Ray Serve for scalable, intuitive model serving.. Watch the live event video"}, {"role": "assistant", "content": "https://youtu.be/7-DlqvaPrTE"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Ray Summit is about Ray, the open-source Python framework for building distributed applications that run at any scale. This inaugural, two-day conference showcases Ray best practices, real-world case studies, and the latest research in AI and other scalable systems built on Ray. It brings together the growing Ray community interested in building scalable AI applications used in e-commerce, media, logistics and transportation, finance, IoT, and more.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Ray Summit 2021"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-summit-2021"}]}
{"messages": [{"role": "user", "content": "Ray aims to provide a universal API for building distributed applications. To achieve this goal requires a distributed system with high levels of performance and reliability. We're looking for engineers with systems software experience that are interested in contributing to the Ray backend.\n\nWe are looking for senior hires as well as less experienced but motivated individuals.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/60d7be88-15c0-45e2-bb95-1f41b746806f"}]}
{"messages": [{"role": "user", "content": "Frontend engineering. Developing scalable distributed applications is notoriously difficult, and debugging these applications is even worse. By exposing the right metrics and visualizations, providing high levels of observability into the underlying system and application behavior, and allowing users to take appropriate actions through the product frontend, we can make the experience of developing, running, and debugging software vastly more efficient and delightful.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/5647629c-ebe3-48b7-950c-159e08ca4934"}]}
{"messages": [{"role": "user", "content": "Scalable machine learning libraries. One of the things that makes Python great is the fact that it has great libraries. Developers can import numpy and pandas and start building powerful applications. But in the distributed setting today, we don\u2019t have libraries. Instead, we have distributed systems like Spark, Horovod, and TensorFlow Serving. These systems cannot easily be composed together and used as elements of a larger application. For example, an online learning system that ingests streaming data, incrementally trains new recommendation models, and then serves recommendations to users will have to stitch together three different distributed systems (one for streaming, one for training, and one for serving) just to build a single application. In the future, people will build these kinds of applications by importing powerful distributed libraries from a rich ecosystem and by composing them together to build new applications. Help us build that ecosystem. This will include libraries for reinforcement learning, hyperparameter tuning, experiment management, model serving, distributed training, and more. Part of this work will be open source as part of Ray.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/710a2429-703a-4c91-b6c9-c5b0cb449e66"}]}
{"messages": [{"role": "user", "content": ". Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/ccc9b235-64c4-43bd-9545-d79a9b8b9df0"}]}
{"messages": [{"role": "user", "content": "One of the things that makes Python great is the fact that it has great libraries. Developers can import numpy and pandas and start building powerful applications. But in the distributed setting today, we don\u2019t have libraries. Instead, we have distributed systems like Spark, Horovod, and TensorFlow Serving. These systems cannot easily be composed together and used as elements of a larger application. For example, an online learning system that ingests streaming data, incrementally trains new recommendation models, and then serves recommendations to users will have to stitch together three different distributed systems (one for streaming, one for training, and one for serving) just to build a single application. In the future, people will build these kinds of applications by importing powerful distributed libraries from a rich ecosystem and by composing them together to build new applications. Help us build that ecosystem. This will include libraries for reinforcement learning, hyperparameter tuning, experiment management, model serving, distributed training, and more. Part of this work will be open source as part of Ray.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/710a2429-703a-4c91-b6c9-c5b0cb449e66"}]}
{"messages": [{"role": "user", "content": "RLlib is an open-source library for reinforcement learning that offers both high scalability and a unified API for a variety of applications. We're looking for software engineers with existing machine learning experience that are interested in continuing to improve RLlib.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/186d9b8d-3fee-4e07-bb8e-49e85cf33d6b"}]}
{"messages": [{"role": "user", "content": "Developer Relations will connect with developers and speak externally about technologies on conference panels, at meet ups, and on blogs. Your work fosters a community of developers integrating with Ray and Anyscale technologies. Externally, you will work on our YouTube channels, in podcasts and trainings, or support channels to troubleshoot and debug technical problems encountered by developers. Internally, you will work with product engineering teams to improve products by conveying feedback from developers, reviewing and contributing to designs, writing production ready code, and testing new features.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/447b795c-9655-4bb2-a116-1cc5fe1e163a"}]}
{"messages": [{"role": "user", "content": "By shaping our online presence on Twitter, Facebook, blogs, and other venues, you will help support, grow, and define the Ray community. For Anyscale, you will be writing and presenting about the product, both to internal and external audiences, in a way that influences the desired behavior. We are looking for machine learning enthusiasts with a passion for communication and experimentation who are scrappy executors who can find creative ways to get things done.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/e5bb28cf-51ae-4005-b12b-2cffdb2d81dd"}]}
{"messages": [{"role": "user", "content": "We are looking for a recruiter to do whatever it takes to grow and scale our team. Responsibilities will include finding creative ways to source the best candidates, delivering a delightful candidate experience, implementing scalable processes, and using data to constantly refine our processes.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/32307f4b-5e83-4673-8301-992a82e726bc"}]}
{"messages": [{"role": "user", "content": "Anyscale gives you the power of the cloud with the simplicity of your laptop.\n\nSign up for the private beta.. Enter email"}, {"role": "assistant", "content": "8748d4f8ce"}]}
{"messages": [{"role": "user", "content": "The Ray Summit brings together developers, machine learning practitioners (especially on deep learning and reinforcement learning), data scientists, DevOps professionals, and cloud-native architects interested in building scalable data and AI applications. The conference is centered around Ray, an open source platform that enables developers to write their applications at any scale. . Register Now"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-summit-2021"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Population Based Training (PBT) is a method for hyperparameter optimization algorithm that trains many models in parallel and uses information from the entire population to refine hyperparameters and allocate more resources to promising configurations. Ray Tune is one of the only libraries to offer a distributed implementation of PBT. In this talk, we will compare PBT against other hyperparameter optimization algorithms to show why PBT is more cost efficient, show how to use PBT with Tune, and give an update on some recent PBT improvements in Ray. Finally, we will discuss a new algorithm, Population Based Bandits, that combines PBT with Bayesian Optimization, and was added to Tune in v1.0.1.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}, {'type': 'underline'}], 'value': 'Schedule', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '10:00am - 10:05am: Introductions and welcome', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '10:05am - 10:30am: Population Based Training with Ray Tune', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '10:30am - 11:00am:', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'italic'}], 'value': ' ', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': 'Audience Q&A', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch video"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=iBVveUT72jU"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Dan Wallach, Professor in the Departments of Computer Science and Electrical and Computer Engineering and a Rice Scholar at the Baker Institute for Public Policy at Rice University in Houston, Texas, discusses the design of Arlo-e2e. ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Live Q&A follows the presentation. ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch video"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=m7r33EuN6Zw&t=8s"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Optimizing machine behavior in supply chain and industrial operations has been constrained by the inability of traditional solvers to handle complexity. Multi-objectives, multi-agents and low latency all presented problems. Deep reinforcement learning has produced significant performance gains in problems ranging from machine scheduling, order sequencing, autonomous vehicle routing, and price prediction. In this talk, Chris Nicholson (Pathmind) will discuss how these solutions learned new behavior while using Ray and RLlib.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Audience Q&A follows the presentation.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch video"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=n4erTp67b_0&t=204s"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Ray autoscaler is the core engine for running distributed Ray applications and the most used Ray library. Autoscaler runs under the hood with every Ray cluster launched. It manages the entire cluster of nodes based on demand and the user\u2019s application. Autoscaler dynamically determines how many nodes and which types of nodes are running at a given time, how many to launch, how many to terminate, how efficient the application will run and more.\\nIn this talk, Ameer  gives a glimpse into Ray autoscaler: the algorithm it uses to schedule resources and the different recent new features added to it including placement groups, directly requesting resources, and multi node types.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch video"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=BJ06eJasdu4&t=9s"}]}
{"messages": [{"role": "user", "content": "Scalable machine learning, \nScalable Python, for everyone. WATCH ON DEMAND"}, {"role": "assistant", "content": "https://www.anyscale.com/event-category/ray-summit"}]}
{"messages": [{"role": "user", "content": ". Watch RS20"}, {"role": "assistant", "content": "https://www.youtube.com/playlist?list=PLzTswPQNepXlr2L75tZt7l8tyVZkO-RVt"}]}
{"messages": [{"role": "user", "content": "Join channel"}, {"role": "assistant", "content": "https://docs.google.com/forms/d/e/1FAIpQLSfAcoiLCHOguOm8e7Jnn-JJdZaCxPGjgVCvFijHB5PLaQLeig/viewform?usp=send_form"}]}
{"messages": [{"role": "user", "content": "Read the code"}, {"role": "assistant", "content": "https://github.com/ray-project/ray"}]}
{"messages": [{"role": "user", "content": "Follow us"}, {"role": "assistant", "content": "https://twitter.com/raydistributed"}]}
{"messages": [{"role": "user", "content": "Ask questions"}, {"role": "assistant", "content": "https://discuss.ray.io/"}]}
{"messages": [{"role": "user", "content": "Charles He\nChief Architect of Computing and Storage, Ant Group"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=Wwv9YNlXx0Q&list=PLzTswPQNepXlr2L75tZt7l8tyVZkO-RVt&index=2&t=6s"}]}
{"messages": [{"role": "user", "content": "Edward Oakes\nProduct Engineer, Anyscale"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=8GTd8Y_JGTQ&list=PLzTswPQNepXlr2L75tZt7l8tyVZkO-RVt"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'The growth of data and healthcare demand has become exceedingly challenging to fulfill the primary objective of a physician: to treat and care for patients with the utmost compassion and to heal their conditions with the greatest skills.  Physicians have been the sole stewards of complex medical therapy because the practice of medicine and the skills required need experience, exposure and iteration on the medical knowledge and understanding of disease.  The experience collected to navigate the disease states, treatment action and next steps to build the expert opinions to steer the patient towards the best outcomes and save lives is developed over more than decades.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '\\nAccessibility is a big challenge to healthcare as we have  witnessed.  The potential of healthcare data is currently underutilized and has the potential to prevent the next pandemic.  Medical research is effective but slow, which leads to poor population representation.  The technology this presentation intends to introduce is the revolutionary next step for medicine. ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '\\nAudience Q&A follows the presentation. ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch video"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=Kd6262ymAkM&t=1277s"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Ray Serve is an open-source library for serving machine learning models at scale.\\xa0 In this talk, we will demonstrate some new features of Ray Serve, including (1) an integration with the open-source ML lifecycle management platform MLflow, and (2) an easy way to use Ray Serve to scale up an existing Python web server.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch video"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=DqgwRAKhIUs"}]}
{"messages": [{"role": "user", "content": "Easily develop and deploy distributed Python and machine learning applications, at any scale.. Sign up for beta"}, {"role": "assistant", "content": "https://www.anyscale.com/beta"}]}
{"messages": [{"role": "user", "content": "Modern workloads, especially in machine learning and artificial intelligence, require immense amounts of compute \u2014 which is only possible through distributed execution. \n\nHowever, building and running distributed apps is hard, and remains inaccessible to most developers. Ray was created at the UC Berkeley RISELab to address this challenge and make distributed computing simple, flexible, and accessible to all engineers. \n. Learn more about Ray"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-open-source"}]}
{"messages": [{"role": "user", "content": "Ray simplifies distributed computing. Anyscale simplifies building, running and managing Ray applications. By eliminating infrastructure and cluster management from the equation, Anyscale lets you focus on your application, and reduce time to market. \n. Learn more about the Anyscale platform"}, {"role": "assistant", "content": "https://www.anyscale.com/product"}]}
{"messages": [{"role": "user", "content": "Sign up for our early access program to try out the infinite laptop experience on Anyscale. \n. Sign up for the Beta"}, {"role": "assistant", "content": "https://www.anyscale.com/beta"}]}
{"messages": [{"role": "user", "content": "Develop and run production workloads at scale as simply as running on your laptop.\n. Sign up for the Beta"}, {"role": "assistant", "content": "https://www.anyscale.com/beta"}]}
{"messages": [{"role": "user", "content": "Sign up for our early access program to try out the infinite laptop experience on Anyscale.. Get started"}, {"role": "assistant", "content": "https://www.anyscale.com/beta"}]}
{"messages": [{"role": "user", "content": "Ray is an open source framework that provides a simple, flexible, and universal API for building and running distributed applications. . Get started"}, {"role": "assistant", "content": "https://docs.ray.io/en/master/auto_examples/overview.html"}]}
{"messages": [{"role": "user", "content": ". Register"}, {"role": "assistant", "content": "https://www.anyscale.com/production-rl-summit?utm_source=anyscale&utm_medium=events-ticket&utm_id=rl-summit"}]}
{"messages": [{"role": "user", "content": "Join us to build the future of distributed computing. See all open roles"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale"}]}
{"messages": [{"role": "user", "content": "Follow along these short tutorials to begin your Ray journey.. Get started"}, {"role": "assistant", "content": "https://docs.ray.io/en/master/auto_examples/overview.html"}]}
{"messages": [{"role": "user", "content": "Learn how to get started with RLlib for scalable reinforcement learning, from training to serving. . Watch the video "}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/12/01/rllib-scalable-rl-training-and-serving-in-the-cloud-with-ray"}]}
{"messages": [{"role": "user", "content": "Missed Ray Summit? All the sessions and tutorials are now available on-demand.. Watch now"}, {"role": "assistant", "content": "https://www.anyscale.com/event-category/ray-summit"}]}
{"messages": [{"role": "user", "content": "New to Ray? Jump-start your learning with this free hands-on tutorial on Ray Core. . Watch the tutorial"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/06/24/ray-core-tutorial"}]}
{"messages": [{"role": "user", "content": ". Watch Demo"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/06/22/anyscale-demo-machine-learning-application-from-dev-to-prod"}]}
{"messages": [{"role": "user", "content": "Learn how Ray libraries (eg., Ray Tune, Ray Serve, etc) help you easily scale every step of your ML pipeline \u2014 from model training and hyperparameter search to inference and production serving.. Watch the video"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/11/17/Scaling-Machine-Learning-Workloads-with-Ray"}]}
{"messages": [{"role": "user", "content": "Get a customized demo to see how Ray and Anyscale can help your team cross the scaling gap in AI. \n. Contact us"}, {"role": "assistant", "content": "https://www.anyscale.com/signup"}]}
{"messages": [{"role": "user", "content": "Join us in San Francisco on August 22 for hands-on training and August 23-24 for the general summit! Get your in-person Ray Summit pass now for $100 (or $150 including training).. Register now"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-summit-2022?utm_source=anyscale&utm_medium=website&utm_campaign=ray_summit_2022&utm_content=home_hero_reg"}]}
{"messages": [{"role": "user", "content": "Ray, the fastest growing open source framework in distributed AI, makes it radically simple for developers to scale the toughest AI workloads \u2014 from deep learning to model serving \u2014 from their laptop to any cloud. . Learn more"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-open-source"}]}
{"messages": [{"role": "user", "content": "Anyscale is a fully-managed Ray offering, from the creators of Ray. It accelerates building, scaling and deploying AI applications on Ray by eliminating the need to build and manage complex infrastructure.. Learn more"}, {"role": "assistant", "content": "https://www.anyscale.com/product"}]}
{"messages": [{"role": "user", "content": "With plans to double our engineering, product, and design teams over the next year, we are looking for a Technical Recruiter to help us scale! As one of the first recruiters on board, you will be a strategic partner in finding creative ways to attract talent, delivering a delightful candidate experience, implementing scalable processes, and, of course, growing our teams.\n\nWe are looking for passionate, motivated people who are excited to build tools to power the next generation of cloud applications. We are excited to build a diverse team and encourage all to apply!. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/13fe36e9-caaf-46ea-846f-cebb36b1122b"}]}
{"messages": [{"role": "user", "content": "It's an exciting time for Anyscale as we transition from focusing solely developing our product to pushing it out to market. We're looking for an experienced go-to-market recruiter to grow our Sales and Marketing teams (and beyond) as we build our product and GTM strategy. As one of the first recruiters on board, you will be a strategic partner in finding creative ways to attract talent, delivering a delightful candidate experience, implementing scalable processes, and, of course, growing our teams.\n\nWe are looking for passionate, motivated people who are excited to build tools to power the next generation of cloud applications. We are excited to build a diverse team and encourage all to apply!. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/57492dd2-1e69-48ec-9b68-4e8df0f66ed0"}]}
{"messages": [{"role": "user", "content": "The Applications team is responsible for creating the suite of tools and services that help create production quality applications using Ray. The product is the user\u2019s primary interface into the world of Anyscale and by building a polished, stable, and well-designed product, we are able to enable a magical developer experience for our users.\n\nApplications engineers help design and implement the features that can simplify or automate many of the processes and components of creating a production-grade application, including development, debugging, deployment, operations, and monitoring. Beyond the user-facing features, applications engineers help build out critical pieces of infrastructure and architecture needed to power our platform at scale.\n\nWith a taste for good products, a willingness to work with and understand the user base, and technical talent to build high quality software, the applications engineer can help build a delightful experience for our users from new developers learning to use Ray to businesses powering their products on Anyscale.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/5647629c-ebe3-48b7-950c-159e08ca4934"}]}
{"messages": [{"role": "user", "content": "We\u2019re looking for our first Content Marketer to help us communicate the story and value of Anyscale in all marketing content. From packing a punch into 280 characters to crafting compelling copy for an email drip campaign to agonizing over the best 7 words to communicate the essence of a launch in a banner, you will be responsible for planning, writing, and editing marketing content for various formats and channels. As the first content marketer at Anyscale, this is an impactful role with a potential to truly shape our story, tone, and voice for years to come. . Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/577dd9a8-626a-449b-b57f-5269944d55ad"}]}
{"messages": [{"role": "user", "content": "Help build the systems and tooling powering our corporate infrastructure! As the first member of our corporate engineering team, you will help provide infrastructure services and solutions to internal teams. This will involve building services and solutions that provide infrastructure, automation, self-service, and observability to support the scaling of our business.\n\nAs the first member of this team, we are looking for someone who can build solutions and design processes from scratch and work effectively across the organization to improve the security and productivity of our teams (one example: self-service laptop provisioning tools).\n\nYou might think of Corporate Engineering as an IT group, but at Anyscale it\u2019s not your typical IT function! You will get to be part of building a first-class product/engineering function, focused on maximizing beneficial outcomes rather than constraining costs. In other words, an IT that is awesome and not just a ticket-closing workshop.. Apply"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale/eea56b4e-a5cd-4be7-b4a5-9344764fa4e3"}]}
{"messages": [{"role": "user", "content": "Develop on your laptop and then scale the same Python code elastically across hundreds of nodes or GPUs on any cloud \u2014 with no changes. . Learn more"}, {"role": "assistant", "content": "https://www.ray.io/"}]}
{"messages": [{"role": "user", "content": "Native Ray libraries \u2014 such as Ray Tune and Ray Serve \u2014 lower the effort to scale the most compute-intensive machine learning workloads, such as hyperparameter tuning, training deep learning models, and reinforcement learning. For example, get started with distributed hyperparameter tuning in just 10 lines of code. \n. Explore all libraries and integrations"}, {"role": "assistant", "content": "https://www.anyscale.com//ray.io"}]}
{"messages": [{"role": "user", "content": "From detection of geospatial anomalies to real-time recommendation, explore the stories of teams scaling machine learning on Ray.  \n. See all stories"}, {"role": "assistant", "content": "https://www.anyscale.com/user-stories"}]}
{"messages": [{"role": "user", "content": "From a dedicated Slack channels to in-person meetups, we have the resources you need to get started and be successful with Ray.. Explore other ways to connect"}, {"role": "assistant", "content": "https://www.anyscale.com//ray.io/community"}]}
{"messages": [{"role": "user", "content": "Reference guides, tutorials, and examples to help you get started on and advance your Ray journey.. Read the docs"}, {"role": "assistant", "content": "https://www.anyscale.com//docs.ray.io"}]}
{"messages": [{"role": "user", "content": "Join the forum to get technical help and share best practices and tips with the Ray community.. Join the forum"}, {"role": "assistant", "content": "https://www.anyscale.com//discuss.ray.io"}]}
{"messages": [{"role": "user", "content": "Connect with other users and project maintainers on the Ray Slack channel.. Join the Slack"}, {"role": "assistant", "content": "https://www.anyscale.com//docs.google.com/forms/d/e/1FAIpQLSfAcoiLCHOguOm8e7Jnn-JJdZaCxPGjgVCvFijHB5PLaQLeig/viewform"}]}
{"messages": [{"role": "user", "content": "A fully managed solution for Ray, from the creators of Ray. \n. Try Anyscale"}, {"role": "assistant", "content": "https://www.anyscale.com/signup"}]}
{"messages": [{"role": "user", "content": "Learn why leading teams are trusting Ray as their distributed computing engine for scaling their AI workloads. \n. What is Ray?"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-open-source"}]}
{"messages": [{"role": "user", "content": "Migrate your existing Ray workloads to Anyscale with no code changes. Experience the magic of limitless scale at your fingertips.\n. Get started on Anyscale"}, {"role": "assistant", "content": "https://www.anyscale.com/signup"}]}
{"messages": [{"role": "user", "content": "News. Anyscale Announces Ray Summit 2022, the Industry Conference for Scalable AI and Python Applications"}, {"role": "assistant", "content": "https://www.globenewswire.com/news-release/2022/07/21/2483863/0/en/Anyscale-Announces-Ray-Summit-2022-the-Industry-Conference-for-Scalable-AI-and-Python-Applications-Featuring-Speakers-from-Uber-Meta-IBM-and-AI-Experts-from-Global-Organizations.html"}]}
{"messages": [{"role": "user", "content": "The reinforcement learning event designed for practitioners \n. Register"}, {"role": "assistant", "content": "https://hopin.com/events/production-rl-summit"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'This talk will cover Ray\u2019s overview, architecture, core concepts, and primitives, such as remote Tasks and Actors; briefly discuss Ray native libraries (Ray Tune, Ray Train, Ray Serve, Ray Datasets, RLlib); and Ray\u2019s growing ecosystem.\\n\\nThrough a demo using XGBoost for classification, we will demonstrate how you can scale training, hyperparameter tuning, and inference\u2014from a single node to a cluster, with tangible performance difference when using Ray.\\n\\nThe takeaways from this talk are :', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Learn Ray architecture, core concepts, and Ray primitives and patterns', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Why Distributed computing will be the norm not an exception', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'How to scale your ML workloads with Ray libraries:', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Training on a single node vs. Ray cluster, using XGBoost with/without Ray', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Hyperparameter search and tuning, using XGBoost with Ray and Ray Tune', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Inferencing at scale, using XGBoost with/without Ray', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'unordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://www.meetup.com/Boulder-Denver-Data-AI-Meetup/events/283085298/'}, 'content': [{'data': {}, 'marks': [], 'value': 'Register >>', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'heading-1'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch Video"}, {"role": "assistant", "content": "https://youtu.be/LmROEotKhJA"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'But distributed computing is not easy. It has its challenges. Building distributed applications today requires tons of expertise. For many developers, it is out of reach. Current solutions to these challenges have their shortcomings and tradeoff.\\n\\nRay aims to address these shortcomings. As a general-purpose distributed computing framework, it makes programming a cluster of machines as easy as programming a laptop, thereby enabling many more developers and practitioners to take advantage of the advances in cloud computing and scale their machine learning workloads to solve harder problems, without needing to be experts in distributed systems. Besides a core general-purpose distributed-compute system, Ray encompasses a collection of state-of-the-art native libraries targeting scalable machine learning. These include libraries for hyperparameter tuning, distributed training, reinforcement learning, model serving, and last-mile ML data pre-processing and ingestion for model training.\\n\\nThis talk will introduce Ray\u2019s overview; survey its ecosystem of both native and integrated ML libraries; and discuss key applications and developments in the Ray ecosystem, drawing upon lessons from discussions with practitioners over the years of developing Ray with the community\u2014and at Anyscale. In particular, we will demonstrate how you can easily scale three common ML workloads, from your laptop to the cluster, with Ray\u2019s native libraries: training, hyperparameter tuning and optimization (HPO), and large-scale batch inference.\\n\\nUsing the popular XGBoost for classification, we will show how you can scale model training, hyperparameter tuning, and inference\u2014from a laptop or single node to a Ray cluster, with tangible performance difference when using Ray.\\n\\nThe takeaways from this talk are :', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Why distributed computing has become the norm and necessity, not an exception\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Learn Ray\u2019s architecture, core concepts, and programming primitives\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Understand Ray\u2019s ecosystem of scalable ML libraries\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Easily extend or transition your laptop to a Ray cluster\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Scale three ML workloads using Ray\u2019s native libraries\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Training on a single node vs. Ray cluster, using XGBoost with/without Ray\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Tuning HPO using XGBoost with Ray and Ray Tune\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Inferencing at scale, using XGBoost with/without Ray', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'unordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://www.youtube.com/watch?v=sfTymZyYvGA'}, 'content': [{'data': {}, 'marks': [], 'value': 'Watch Video', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://www.youtube.com/watch?v=sfTymZyYvGA'}, 'content': [{'data': {}, 'marks': [], 'value': ' >>', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'heading-1'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch Video"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=sfTymZyYvGA"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'This talk will cover Ray\u2019s overview, architecture, core concepts, and design patterns. We will demonstrate how Ray can scale training, hyperparameter tuning, and inference from a single node to a cluster, with tangible performance benefits.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch video"}, {"role": "assistant", "content": "https://www.meetup.com/Data-Science-DC/events/283823601?utm_medium=referral&utm_campaign=share-btn_savedevents_share_modal&utm_source=link"}]}
{"messages": [{"role": "user", "content": "Get your free copy of early release chapters of Learning Ray, the first and only comprehensive book on Ray and its ecosystem.. Get your free copy"}, {"role": "assistant", "content": "https://www.anyscale.com/asset/book-learning-ray-oreilly"}]}
{"messages": [{"role": "user", "content": "Get early release chapters of the first and only comprehensive book on Ray and its ecosystem. . Watch now"}, {"role": "assistant", "content": "https://www.anyscale.com/asset/book-learning-ray-oreilly"}]}
{"messages": [{"role": "user", "content": "Scalable machine learning,\nScalable Python, for everyone. Submit a talk"}, {"role": "assistant", "content": "https://myeventi.events/raysummit22/cfp/"}]}
{"messages": [{"role": "user", "content": "We are currently accepting proposals for conference talks. If you have a story about your Ray use case, how you\u2019re using the Ray ecosystem to build ML/AI applications at scale, your production journey with Ray employing MLOps best practices, or research projects using Ray and related distributed computing technologies, we want to hear from you. This is a great chance to share your story with the Ray community.\n\nThe deadline to submit has been extended to __April 18, 2022__.. Submit a talk"}, {"role": "assistant", "content": "https://myeventi.events/raysummit22/cfp/"}]}
{"messages": [{"role": "user", "content": "Machine learning and AI are urgent competitive necessities, but companies struggle with scale, production, and expertise. With Ray and Anyscale, developers of all skill levels can easily build applications that run at any scale, from a laptop to a data center.. Explore a career with Anyscale"}, {"role": "assistant", "content": "https://www.anyscale.com/careers"}]}
{"messages": [{"role": "user", "content": ". Discover more user stories"}, {"role": "assistant", "content": "https://www.anyscale.com/user-stories"}]}
{"messages": [{"role": "user", "content": "We\u2019re a team of builders leading the movement to democratize machine learning. Come help us make distributed computing simple and accessible to every developer.. Explore open roles"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale"}]}
{"messages": [{"role": "user", "content": ". See all open roles"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale"}]}
{"messages": [{"role": "user", "content": "Share your Ray story at Ray Summit! The deadline to submit is April 18.. Submit your talk"}, {"role": "assistant", "content": "https://www.myeventi.events/raysummit22/cfp?utm_source=anyscale&utm_medium=website&utm_campaign=ray_summit_2022&utm_content=promo_box_cfp"}]}
{"messages": [{"role": "user", "content": "Extend what you can do with Ray by attending hands-on, expert-led workshops and deep dives. See the agenda"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-summit-2022/agenda"}]}
{"messages": [{"role": "user", "content": "Mingle with the world\u2019s top minds in distributed computing, machine learning, and AI"}, {"role": "assistant", "content": "https://www.anyscale.com/"}]}
{"messages": [{"role": "user", "content": "Do you have a story about how you\u2019re using the Ray ecosystem to build ML/AI applications at scale? Submit your talk to the Ray Summit 2022 Call for Papers \u2014 the deadline to submit is April 18.. Submit your talk"}, {"role": "assistant", "content": "https://www.myeventi.events/raysummit22/cfp/"}]}
{"messages": [{"role": "user", "content": "Come connect with the global community of thinkers and disruptors who are building and deploying the next generation of AI and ML applications.. Save your spot"}, {"role": "assistant", "content": "https://www.myeventi.events/raysummit22/attendee/"}]}
{"messages": [{"role": "user", "content": ". Join the channel"}, {"role": "assistant", "content": "https://docs.google.com/forms/d/e/1FAIpQLSfAcoiLCHOguOm8e7Jnn-JJdZaCxPGjgVCvFijHB5PLaQLeig/viewform?usp=send_form"}]}
{"messages": [{"role": "user", "content": ". Follow us"}, {"role": "assistant", "content": "https://twitter.com/Ray_Summit_Live"}]}
{"messages": [{"role": "user", "content": ". Contribute to Ray"}, {"role": "assistant", "content": "https://github.com/ray-project/ray"}]}
{"messages": [{"role": "user", "content": ". Ask a question"}, {"role": "assistant", "content": "https://discuss.ray.io/"}]}
{"messages": [{"role": "user", "content": "Ray Summit is the ideal place to engage with the Ray community \u2014 a thriving group of machine learning, AI, and distributed computing professionals who are building the future of scalable Python applications. If you're interested in becoming a sponsor, please reach out to <a href=mailto:sponsorships@anyscale.com>sponsorships@anyscale.com</a> for more information.. Contact us"}, {"role": "assistant", "content": "mailto:sponsorships@anyscale.com"}]}
{"messages": [{"role": "user", "content": "Now\u2019s your chance to join the global Ray community in San Francisco to explore the future of scalable AI.. Save Your Spot Now"}, {"role": "assistant", "content": "https://www.myeventi.events/raysummit22/attendee/"}]}
{"messages": [{"role": "user", "content": "Learn how to use Ray Serve to build and operationalize multi-model inference pipelines.. Watch now"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2022/04/14/productionizing-ml-at-scale-with-ray-serve"}]}
{"messages": [{"role": "user", "content": "Join us in San Francisco on September 18-20 for three days of keynotes, trainings, and technical sessions.. Register now"}, {"role": "assistant", "content": "https://raysummit.anyscale.com/?utm_source=anyscale&utm_medium=website&utm_campaign=ray_summit_2023&utm_content=live-event"}]}
{"messages": [{"role": "user", "content": "Start with a hands-on exploration of the core Ray API for distributed workloads, then move on to a quick introduction to Ray\u2019s native libraries.. Learn more"}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/3YJP8BqPhXtSZJUsgMUmBa/f30b93edf0165a46d198875f68f5e773/Ray-Summit-Training1.pdf"}]}
{"messages": [{"role": "user", "content": "Learn how Ray Serve makes it easy to deploy, operate, and scale a machine learning model using Ray Serve APIs.. Learn more"}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/7p7n5gmoqQuxt4XIIqcPLo/17026ccd42a32c778e1fca5f18847e0b/Ray-Summit-Training2.pdf"}]}
{"messages": [{"role": "user", "content": "Learn how to apply cutting-edge reinforcement learning (RL) techniques in production with Ray RLlib.. Learn more"}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/U7JTeEkvjkzpiS3m7h3lE/ab305462657e79833126ad52819fd199/Ray-Summit-Training3.pdf"}]}
{"messages": [{"role": "user", "content": ". Learn more"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-summit-2022/agenda/sessions/190"}]}
{"messages": [{"role": "user", "content": "Ready to help us build the next generation of scalable AI? Check out our open roles across Engineering, Operations, Marketing, Recruiting, Product, and Sales.. Explore open roles"}, {"role": "assistant", "content": "https://jobs.lever.co/anyscale"}]}
{"messages": [{"role": "user", "content": ""}, {"role": "assistant", "content": "https://www.globenewswire.com/en/news-release/2023/05/31/2679749/0/en/Anyscale-Launches-Aviary-Open-Source-Infrastructure-to-Simplify-Large-Language-Model-Deployment.html"}]}
{"messages": [{"role": "user", "content": "Ray is an open source project with a vibrant and growing community. Even before Ray Summit begins, you can explore ways to connect with other members, get technical help, share best practices, contribute to the project, and stay informed on the latest developments.. Join the Ray Community"}, {"role": "assistant", "content": "https://www.ray.io/community"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Modern machine learning (ML) workloads, such as deep learning and large-scale model training, are compute-intensive and require distributed execution.\\xa0', 'nodeType': 'text'}, {'data': {'uri': 'https://github.com/ray-project/ray'}, 'content': [{'data': {}, 'marks': [], 'value': 'Ray', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '\\xa0is an open-source, distributed framework from UC Berkeley\u2019s\\xa0', 'nodeType': 'text'}, {'data': {'uri': 'https://rise.cs.berkeley.edu/'}, 'content': [{'data': {}, 'marks': [], 'value': 'RISELab', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '\\xa0that easily scales Python applications and ML workloads from a laptop to a cluster, with an emphasis on the unique performance challenges of ML/AI systems. It is now used in many production deployments.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': \"This talk will give an overview of Ray and Ray's architecture, core concepts, and primitives, such as remote Tasks and Actors; briefly discuss Ray's native libraries (Ray Tune, Ray Train, Ray Serve, Ray Datasets, RLlib); and dive into Ray\u2019s growing ecosystem.\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Key takeaways:', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Learn Ray architecture, core concepts, and Ray primitives and patterns', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Find out why distributed computing will be the norm, not an exception', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'See how to scale your ML workloads with Ray libraries:', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Training on a single node vs. Ray cluster, using XGBoost with/without Ray', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Hyperparameter search and tuning, using XGBoost with Ray Tune', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Inferencing at scale, using XGBoost with/without Ray', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'unordered-list'}], 'nodeType': 'list-item'}], 'nodeType': 'unordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://www.meetup.com/SF-Bay-ACM/events/285767313/'}, 'content': [{'data': {}, 'marks': [], 'value': 'Register >>', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'heading-1'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch Video"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=Fc-xuUBs5MY"}]}
{"messages": [{"role": "user", "content": ". Read more"}, {"role": "assistant", "content": "https://www.businesswire.com/news/home/20191217005078/en/Founders-of-Open-Source-Project-Ray-Launch-Anyscale-with-20.6M-in-Funding-to-Democratize-Distributed-Programming"}]}
{"messages": [{"role": "user", "content": "Datanami. Read more"}, {"role": "assistant", "content": "https://www.datanami.com/2017/03/28/meet-ray-real-time-machine-learning-replacement-spark/"}]}
{"messages": [{"role": "user", "content": "Richard Liaw (engineering manager, Anyscale)\nEric Liang (software engineer, Anyscale). Learn more"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-summit-2022/agenda/sessions/226"}]}
{"messages": [{"role": "user", "content": "__Richard Liaw__ (Engineering Manager, Anyscale)\n__Eric Liang__ (Software Engineer, Anyscale)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Edward Oakes__ (Software Engineer, Anyscale)\n__Simon Mo__ (Software Engineer, Anyscale)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Ali Kanso__ (Principal Software Engineer, Microsoft)\n__Jiaxin Shan__ (Software Engineer, ByteDance)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Sven Mika__ (Machine Learning Engineer, Anyscale)\n__Jun Gong__ (Software Engineer, Anyscale)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Stephanie Wang__ (Software Engineer, Anyscale)\n__Jiajun Yao__ (Software Engineer, Anyscale)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Clark Zinzow__ (Software Engineer, Anyscale)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__SangBin Cho__ (Software Engineer, Anyscale)\n__Ricky Xu__ (Software Engineer, Anyscale)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Xu Ning__ (Senior Engineering Manager, Uber)\n__Michael Mui__ (Staff Software Engineer, Uber AI)\n__Di Yu__ (Sr. Software Engineer, Uber Technologies, Inc.)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Isaac Vidas__ (Machine Learning Platform Tech Lead, Shopify)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Lukas Biewald__ (CEO/Founder, Weights & Biases)\t"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "__Mark Saroufim__ (Machine Learning Engineer, Meta)"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "Datanami"}, {"role": "assistant", "content": "https://www.datanami.com/2022/08/23/anyscale-branches-beyond-ml-training-with-ray-2-0-and-ai-runtime/"}]}
{"messages": [{"role": "user", "content": "Business Insider"}, {"role": "assistant", "content": "https://www.businessinsider.com/anyscale-berkeley-databricks-206-million-a16z-2019-12"}]}
{"messages": [{"role": "user", "content": "VentureBeat"}, {"role": "assistant", "content": "https://venturebeat.com/ai/ray-the-machine-learning-tech-behind-openai-levels-up-to-ray-2-0/amp/"}]}
{"messages": [{"role": "user", "content": "SiliconANGLE "}, {"role": "assistant", "content": "https://siliconangle.com/2020/09/30/ray-ai-framework-used-amazon-intel-engineers-marks-1-0-release/"}]}
{"messages": [{"role": "user", "content": "App Developer Magazine "}, {"role": "assistant", "content": "https://appdevelopermagazine.com/ray-1.0-announced-from-anyscale/"}]}
{"messages": [{"role": "user", "content": "Business Insider "}, {"role": "assistant", "content": "https://www.businessinsider.com/uc-berkeley-labs-databricks-sifive-anyscale-riselab-amplab-2021-9"}]}
{"messages": [{"role": "user", "content": "Yahoo News"}, {"role": "assistant", "content": "https://news.yahoo.com/anyscale-adds-40m-bring-ray-132818440.html"}]}
{"messages": [{"role": "user", "content": "TechRepublic "}, {"role": "assistant", "content": "https://www.techrepublic.com/article/how-the-open-source-ray-project-delivers-the-infinite-laptop-for-distributed-computing/"}]}
{"messages": [{"role": "user", "content": "ZDNet "}, {"role": "assistant", "content": "https://www.zdnet.com/article/databricks-cofounders-next-act-shining-a-ray-on-compute-autoscaling/"}]}
{"messages": [{"role": "user", "content": "Forbes "}, {"role": "assistant", "content": "https://www.forbes.com/sites/kenrickcai/2021/12/07/berkeley-research-lab-mints-second-billion-dollar-startup-anyscale/?sh=6436e69f866a"}]}
{"messages": [{"role": "user", "content": "SiliconANGLE"}, {"role": "assistant", "content": "https://siliconangle.com/2021/12/07/anyscale-raises-100m-launches-distributed-multicloud-application-development-platform/"}]}
{"messages": [{"role": "user", "content": "Venture Capital Journal "}, {"role": "assistant", "content": "https://www.venturecapitaljournal.com/anyscale-rallies-100m-series-c/"}]}
{"messages": [{"role": "user", "content": "Datanami "}, {"role": "assistant", "content": "https://www.datanami.com/2021/12/08/anyscale-nabs-100m-unleashes-parallel-serverless-computing-in-the-cloud/"}]}
{"messages": [{"role": "user", "content": "ITPro Today "}, {"role": "assistant", "content": "https://www.itprotoday.com/devops/anyscale-launches-managed-multicloud-platform-scale-mlops"}]}
{"messages": [{"role": "user", "content": "TechTarget "}, {"role": "assistant", "content": "https://www.techtarget.com/searchenterpriseai/feature/Swiss-retailer-uses-open-source-Ray-tool-to-scale-AI-models"}]}
{"messages": [{"role": "user", "content": "SalesTechSeries "}, {"role": "assistant", "content": "https://salestechstar.com/interviews/salestechstar-interview-with-rich-hoyland-head-of-sales-at-anyscale/"}]}
{"messages": [{"role": "user", "content": "Wall Street Journal"}, {"role": "assistant", "content": "https://www.wsj.com/articles/ai-startup-anyscale-adds-99-million-to-andressen-horowitz-led-funding-round-11661254200?mod=hp_lista_pos5"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'We are delighted to host our September Ray Meetup with talks from Ray community users and committers.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/ray-community-meetup-talks-introduction'}, 'content': [{'data': {}, 'marks': [], 'value': 'Introduction deck', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/ray-community-meetup-talks-data-transfer-s3-plasma'}, 'content': [{'data': {}, 'marks': [], 'value': 'Talk 1 deck', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/ray-community-meetup-talks-state-of-ray-serve-20'}, 'content': [{'data': {}, 'marks': [], 'value': 'Talk 2 deck\\xa0', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Agenda:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n(The times are not strict; they may vary slightly.)', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'ordered-list'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': '5:00 p.m.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Welcome remarks, announcements, agenda, Ray Summit 2022 Highlights - Jules Damji, Anyscale', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': '5:10 p.m. Talk 1', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': ': Data transfer speed comparison in a distributed ML application: Ray Plasma Store vs. S3 - ', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'italic'}], 'value': 'Ankur Mohan, Capital One', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': '6:00 p.m.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Q & A', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': '6:10 p.m.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 2:', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'State of Ray Serve in Ray 2.0 - ', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'italic'}], 'value': 'Simon Mo, Anyscale, Ray Team', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': '6: 50 p.m.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Q & A', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'unordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 1: Data transfer speed comparison in a distributed ML application: Ray Plasma store vs. S3', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Abstract', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ':\\nScattering and gathering data within and across nodes in a compute cluster are frequent operations in distributed applications. Thus, an efficient, distributed data store that provides concurrent, high bandwidth R/W for large data is essential for scaling distributed applications. Several choices exist for such data stores. Some options such as network file systems and cloud storage solutions such as S3 are independent of the choice of the distributed computing framework (eg., DASK, Spark, Ray) whereas other options are an integral part of the distributed computing framework (eg., the plasma store with Ray).\\n', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'This talk will present a detailed analysis of the pros and cons of some of these options for distributed data stores, using Ray as the distributed computing framework. We\u2019ll use a speech2text application that needs to load a deep neural network model and scatter this model to several workers that perform the speech2text transcription task on audio files concurrently.\\n', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'We will analyze two scenarios. In the first scenario, the model is downloaded to the plasma store and scattered to workers performing speech2text conversion via object store replication. In the second scenario, each worker downloads the model independently from cloud storage (S3). The analysis of each scenario will consider various possibilities for scheduling the speech2text workers ranging from all workers being scheduled on the same node to all workers executing on separate nodes.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '\\nThe experimental setup will be a RayCluster installed using the Ray-Kubernetes operator.\\nAttendees will come away with a thorough understanding of RayCluster setup on Kubernetes using the operator pattern, and the trade-offs and nuances involved in data transfer in a distributed system\\n', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Bio:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': \"\\xa0Ankur Mohan leads the Machine Learning as a Service (MLaaS) team at Capital One that enables the execution of ML models and workflows on a Kubernetes cluster with assured least privilege data access, compute and network isolation across tenants and robust support for scaling and observability. Prior to Capital One, Ankur led the AI/ML practice at In-Q-Tel, a VC firm. Outside of work, Ankur enjoys biking, kitesurfing, traveling and blogging. The material presented in this talk is Ankur's personal work and unrelated to his job at Capital One.\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 2: State of Ray Serve in Ray 2.0', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Abstract:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': \"\\xa0Ray 2.0 was released in late August, and it covers many features that help you scale out machine learning models serving in production! In this talk, we'll discuss the motivation behind Ray Serve, who's using Ray Serve and why, and recent features and updates in Ray 2.0.\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'In particular, we will cover Ray Serve autoscaling, the brand new deployment feature for multi-mode composition, and update to Serve\u2019s fault tolerance feature on Kubernetes. Bring your questions about ML models in production as well.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Bio:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0Simon Mo is a software engineer working on Ray Serve at Anyscale. Before Anyscale, he was a student at UC Berkeley participating in research at the RISELab. He focuses on studying and building systems for machine learning, in particular, how to make ML model serving systems more efficient, ergonomic, and scalable.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch Video"}, {"role": "assistant", "content": "https://youtu.be/puYhYaGjEm0"}]}
{"messages": [{"role": "user", "content": "Sign up for updates. Sign up"}, {"role": "assistant", "content": "https://share.hsforms.com/1Ee3Gh8c9TY69ZQib-yZJvgc7w85"}]}
{"messages": [{"role": "user", "content": "InsideBigData"}, {"role": "assistant", "content": "https://insidebigdata.com/2022/08/23/anyscale-unveils-ray-2-0-and-anyscale-innovations-at-ray-summit-2022/"}]}
{"messages": [{"role": "user", "content": "SiliconAngle"}, {"role": "assistant", "content": "https://siliconangle.com/2022/08/23/anyscale-raises-99m-build-distributed-ai-computing-platform/"}]}
{"messages": [{"role": "user", "content": "TechTarget"}, {"role": "assistant", "content": "https://www.techtarget.com/searchenterpriseai/news/252524190/New-funding-for-Anyscale-boosts-popular-Ray-AI-platform"}]}
{"messages": [{"role": "user", "content": "Enterprise Talk"}, {"role": "assistant", "content": "https://enterprisetalk.com/quick-bytes/anyscale-raises-usd-99m-to-build-out-its-distributed-ai-computing-platform/"}]}
{"messages": [{"role": "user", "content": "Dataconomy"}, {"role": "assistant", "content": "https://dataconomy.com/2022/08/ray-2-0-ml-tech-framework-is-live/"}]}
{"messages": [{"role": "user", "content": "CNBC"}, {"role": "assistant", "content": "https://www.cnbc.com/2022/08/26/microsoft-tiktok-parent-bytedance-collaborate-on-ai-project-kuberay.html"}]}
{"messages": [{"role": "user", "content": "CIOReview"}, {"role": "assistant", "content": "https://www.cioreview.com/news/ray-summit-to-develop-new-innovations-in-ray-and-the-anyscale-platform-nid-35831-cid-175.html"}]}
{"messages": [{"role": "user", "content": "Use Ray on Anyscale, the unified compute platform from the creators of Ray. Watch Demo"}, {"role": "assistant", "content": "https://www.youtube.com/embed/Q1t9qeDJquI"}]}
{"messages": [{"role": "user", "content": "The Anyscale Platform offers key advantages over Ray open source. It provides a seamless user experience for developers and AI teams to speed development, and deploy AI/ML workloads at scale. Companies using Anyscale benefit from rapid time-to-market and faster iterations across the entire AI lifecycle.\n. Download the Anyscale Platform Overview "}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/32SriyXoFAcTa8xcjGkHej/c5afbef9e487f7e4bfb7594ea097451f/Anyscale_Overview_Datasheet.pdf"}]}
{"messages": [{"role": "user", "content": "<span class=\"text-orange\">Anyscale Workspaces.</span> Workspaces provides an integrated IDE experience that allows teams to edit and run code, install dependencies, monitor jobs and resources across a scalable cluster just like you would on your laptop.\n\n<span class=\"text-orange\">Use the tools you know and already love.</span> Anyscale provides integration and instant setup for popular tools such as VSCode and Jupyter notebook, with Github, Weights & Biases, and more.\n\n<span class=\"text-orange\">Collaborate.</span> Share or clone experiments with a click of a button. Different users can access a workspace with all the same configuration and environments and be productive instantaneously. Learn More"}, {"role": "assistant", "content": "\\accelerate-development-and-scaling-of-ml-and-python-workloads"}]}
{"messages": [{"role": "user", "content": "<span class=\"text-orange\">A unified environment for development and production.</span> Anyscale focuses the experience on a unified environment - run, debug, and test your code at scale on the same cluster configuration with the same software dependencies for both development and production.\n\n<span class=\"text-orange\">Flexible and extensive dependency management.  </span>Anyscale provides different options to manage your dependencies across your cluster. You can use existing base images, bring your own Docker, or use Ray\u2019s runtime environments for faster iteration.\n\n<span class=\"text-orange\">Jobs and services API and SDK.</span> Anyscale provides an easy interface to operationalize your workloads and integrate with your existing deployment tools. Anyscale Jobs support cron jobs, ephemeral cluster creation and retry capabilities, while Anyscale Services provides replica management, no downtime upgrades and high availability.. Learn More"}, {"role": "assistant", "content": "https://www.anyscale.com/seamlessly-move-between-development-and-production"}]}
{"messages": [{"role": "user", "content": "<span class=\"text-orange\">Managed logs, monitoring, and observability.</span> Anyscale provides a production-grade monitoring and observability stack with a managed Grafana and Ray dashboard. Additionally, Anyscale provides production monitoring and notifications for added trust that pipelines are running well.. Learn More"}, {"role": "assistant", "content": "https://www.anyscale.com/monitoring-and-orchestration"}]}
{"messages": [{"role": "user", "content": "Watch this on-demand webinar to learn how to simply scale any AI or Python workload using Ray, the fastest growing unified compute framework for scaling machine learning workloads.\n\nLearn how users are using Ray to build, manage and deploy scalable ML workloads.. Watch Now"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2022/10/12/simplify-scaling-machine-learning-and-python-workloads"}]}
{"messages": [{"role": "user", "content": "The Anyscale Platform offers several key advantages over Ray open source\nand provides a seamless user experience for developers and AI teams to\nspeed development, improve developer productivity and productionize AI/\nML workloads at scale including large data sets. The result is faster time-to-market and faster iterations across the entire AI lifecycle.\n\n__Get started on your existing workloads__ to Anyscale with no code changes. Experience the magic of infinite scale at your fingertips.. Why Anyscale vs Ray"}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/7Le2RvgnMgydY1RaD81jGM/8a235998777c72898c8fb0273d5f6c3c/Ray_open_source-vs-Anyscale_Platform-Comparison.pdf"}]}
{"messages": [{"role": "user", "content": "Get started your existing workloads to Anyscale with no code changes. Experience the magic of infinite scale at your fingertips.. Get Started"}, {"role": "assistant", "content": "https://www.anyscale.com/platform"}]}
{"messages": [{"role": "user", "content": "LinkedIn improved member engagement with a superior Network Quality Service prediction model. See their path to 2x faster training with Ray Tune.. Watch The Video"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/10/20/fast-scalable-hyperparameter-tuning-ray-tune"}]}
{"messages": [{"role": "user", "content": "Learn how Anastasia realized 9x speedup and 87% cost reduction on their demand forecasting use case with Ray Tune.. Read The Story"}, {"role": "assistant", "content": "https://docs.ray.io/en/latest/tune/index.html"}]}
{"messages": [{"role": "user", "content": "Change the way you handle data loading and preprocessing for ML training.. Watch the video"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2022/02/23/ray-datasets-scalable-data-preprocessing-for-distributed-ml"}]}
{"messages": [{"role": "user", "content": "Easily learn everything you need to know to get started with Ray Datasets. Self-guided, interactive documentation for developers of all skill levels.. Go to docs"}, {"role": "assistant", "content": "https://docs.ray.io/en/latest/data/dataset.html"}]}
{"messages": [{"role": "user", "content": "Get started, learn how to use Ray, fast track your projects.. Get started"}, {"role": "assistant", "content": "https://www.anyscale.com/events"}]}
{"messages": [{"role": "user", "content": "Easily learn everything you need to know to get started with Ray. Self-guided, interactive documentation for developers of all skill levels.. Go to docs"}, {"role": "assistant", "content": "https://docs.ray.io/en/latest/tune/index.html"}]}
{"messages": [{"role": "user", "content": "Change the way you handle you scale. Watch the video"}, {"role": "assistant", "content": "https://www.anyscale.com/"}]}
{"messages": [{"role": "user", "content": "Easily learn about RayAIR. Go To Documentation"}, {"role": "assistant", "content": "https://docs.ray.io/en/latest/"}]}
{"messages": [{"role": "user", "content": "Get started your existing workloads to Anyscale with no code changes. Experience the magic of infinite scale at your fingertips.. Get started"}, {"role": "assistant", "content": "https://www.anyscale.com/platform"}]}
{"messages": [{"role": "user", "content": "Migrate your existing workloads to Anyscale with no code changes. Experience the magic of infinite scale at your fingertips.. Get started"}, {"role": "assistant", "content": "https://www.anyscale.com/platform"}]}
{"messages": [{"role": "user", "content": "Wildlife Studios serves in-game offers 3X faster, while simultaneously reducing infrastructure spend by 95% cost, with Ray Serve.. Read Their Story"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/06/22/using-reinforcement-learning-to-optimize-iap-offer-recommendations-in-mobile-games"}]}
{"messages": [{"role": "user", "content": "See how a small team of data scientists build a dynamic, scalable data pipeline service for their user using Ray Serve.. Read Their Story"}, {"role": "assistant", "content": "https://www.anyscale.com/blog/how-ikigai-labs-serves-interactive-ai-workflows-at-scale-using-ray-serve"}]}
{"messages": [{"role": "user", "content": "Get started, learn how to use Ray Serve, and fast track your projects.. Watch the video"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/09/09/building-a-scalable-ml-model-serving-api-with-ray-serve"}]}
{"messages": [{"role": "user", "content": "LinkedIn improved member engagement with a superior Network Quality Service prediction model. See their path to 2x faster training with Ray Tune.. See The Full Story"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/10/20/fast-scalable-hyperparameter-tuning-ray-tune"}]}
{"messages": [{"role": "user", "content": "Learn how Anastasia realized 9x speedup and 87% cost reduction on their demand forecasting use case with Ray Tune.. See The Full Story"}, {"role": "assistant", "content": "https://docs.ray.io/en/latest/tune/index.html"}]}
{"messages": [{"role": "user", "content": "Get started, learn how to use Ray Tune, and fast track your projects.. Watch the video"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/10/20/fast-scalable-hyperparameter-tuning-ray-tune"}]}
{"messages": [{"role": "user", "content": "At OpenAI, we are tackling some of the world\u2019s most complex and demanding computational problems. Ray powers our solutions to the thorniest of these problems and allows us to iterate at scale much faster than we could before. As an example, we use Ray to train our largest models, including ChatGPT.. Story"}, {"role": "assistant", "content": "https://www.businessinsider.com/openai-chatgpt-trained-on-anyscale-ray-generative-lifelike-ai-models-2022-12"}]}
{"messages": [{"role": "user", "content": "Ray and Anyscale empower even the leanest teams to bring AI to production and realize the business potential of AI in record time.. Story"}, {"role": "assistant", "content": "https://www.techtarget.com/searchenterpriseai/feature/Swiss-retailer-uses-open-source-Ray-tool-to-scale-AI-models"}]}
{"messages": [{"role": "user", "content": "We chose Ray as the unified compute backend for our machine learning and deep learning platform because it has allowed us to significantly improve performance and fault tolerance, while also reducing the complexity of our technology stack. Ray has brought significant value to our business.. Story"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/06/22/distributed-xgboost-on-ray"}]}
{"messages": [{"role": "user", "content": "Being able to operate quickly at this massive scale has enabled us to deliver novel solutions towards Dendra Systems\u2019 mission of scaling ecosystem restoration of our biodiverse natural world.. Story"}, {"role": "assistant", "content": "https://www.anyscale.com/blog/how-ray-and-anyscale-make-it-easy-to-do-massive-scale-machine-learning-on"}]}
{"messages": [{"role": "user", "content": "Ray and Anyscale have enabled us to quickly develop, test and deploy a new in-game offer recommendation engine based on reinforcement learning, and subsequently serve those offers 3X faster in production. This resulted in revenue lift and a better gaming experience.. Story"}, {"role": "assistant", "content": "https://www.anyscale.com/blog/wildlife-studios-serves-in-game-offers-3x-faster-at-1-10th-the-cost-with-ray"}]}
{"messages": [{"role": "user", "content": "<b>Ray is an open source unified compute framework</b> for scaling ML and Python workloads. With Ray, training, tuning and serving many models or massive models is reduced to minutes. Learn more about <b>Ray</b>, and the <b>Anyscale Platform</b>, an enterprise-ready managed Ray platform.. Request a Trial"}, {"role": "assistant", "content": "https://www.anyscale.com/signup"}]}
{"messages": [{"role": "user", "content": "New Survey from MLOps Community on LLM use cases, challenges, and solutions. Learn from your peers' experience.. Read it Now"}, {"role": "assistant", "content": "https://www.anyscale.com/asset/llm-survey-report"}]}
{"messages": [{"role": "user", "content": "Announcing Aviary from Anyscale. Quickly select and deploy LLMs for your AI applications.. Learn More"}, {"role": "assistant", "content": "http://anyscale.com/large-language-models"}]}
{"messages": [{"role": "user", "content": "Explore how Ray is blazing a path forward in AI and ML applications at this year\u2019s Ray Summit.. Full Agenda and Registration"}, {"role": "assistant", "content": "https://raysummit.anyscale.com/?utm_source=anyscale&utm_medium=website&utm_campaign=ray_summit_2023&utm_content=live-event"}]}
{"messages": [{"role": "user", "content": "Companies are using Ray to scale ML and Python workloads including everything from data ingest, to preprocessing, hyperparameter tuning, training, and model serving at scale.. Learn More"}, {"role": "assistant", "content": "https://www.anyscale.com/platform"}]}
{"messages": [{"role": "user", "content": ". Get Started"}, {"role": "assistant", "content": "https://www.anyscale.com/platform"}]}
{"messages": [{"role": "user", "content": ". See All"}, {"role": "assistant", "content": "https://www.anyscale.com/user-stories"}]}
{"messages": [{"role": "user", "content": "Wildlife Studios runs Anyscale on AWS to serve in-game offers 3x faster and at 10% of the cost, with the potential for $400,000 in infrastructure savings annually.. Read the blog"}, {"role": "assistant", "content": "https://www.anyscale.com/blog/wildlife-studios-serves-in-game-offers-3x-faster-at-1-10th-the-cost-with-ray"}]}
{"messages": [{"role": "user", "content": "Dendra Systems runs Anyscale on AWS to do massive-scale machine learning on aerial imagery for environmental restoration and planting trees. This involves terabyte-scale processing of image datasets and scaling deep neural network training with the Ray ecosystem. Read the blog.. Read the blog"}, {"role": "assistant", "content": "https://www.anyscale.com/blog/how-ray-and-anyscale-make-it-easy-to-do-massive-scale-machine-learning-on"}]}
{"messages": [{"role": "user", "content": "Switching to running their machine learning workloads with Ray and Anyscale on AWS enabled Anastasia to accelerate their machine learning job completion times by 9x. Furthermore, they reduced the cost of running these workloads by over 80%.. Read the blog"}, {"role": "assistant", "content": "https://www.anyscale.com/blog/how-anastasia-implements-ray-and-anyscale-to-speed-up-ml-processes-9x"}]}
{"messages": [{"role": "user", "content": "Serverless computing is an important direction in the evolution of computing. Marvin Theimer, a distinguished engineer at Amazon speaks about the lessons learned in this domain.. Watch the talk"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/06/23/cloud-computing-made-better"}]}
{"messages": [{"role": "user", "content": "Amazon uses Ray to process petabytes of data every single day. This has led to more than an order of magnitude improvement in scalability, throughput, and cost reduction.. Watch the talk"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/06/22/adventures-in-petabyte-scale-data-lake-table-management-with-ray-arrow-parquet-and-s3"}]}
{"messages": [{"role": "user", "content": "Nixtla uses Ray on AWS to scale forecasting by fitting one million time series models in less than half an hour and for under $30.. Read the blog"}, {"role": "assistant", "content": "https://www.anyscale.com/blog/how-nixtla-uses-ray-to-accurately-predict-more-than-a-million-time-series"}]}
{"messages": [{"role": "user", "content": "Learn how AWS SageMaker and Ray are used together to manage reinforcement larning workflows from perception to controls to optimization and how this combination is used to create end-to-end solutions for power plant and manufacturing plant operations.. Watch the talk"}, {"role": "assistant", "content": "https://www.anyscale.com/events/2021/06/23/introducing-amazon-sagemaker-kubeflow-reinforcement-learning-pipelines-for"}]}
{"messages": [{"role": "user", "content": ". Download"}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/1XdDKVx02vUMBfzhE0DlNl/2127265b77afa8e24be5b6fe9ea4c99d/anyscale-data-sheet-R8.pdf"}]}
{"messages": [{"role": "user", "content": "Learn why thousands of organizations use<span class=\"text-secondary\"> Ray open-source,</span> a unified framework for scalable<br>\ncomputing, to speed AI development and scale machine learning and Python workloads<br>\nand the <span class=\"text-secondary\">Anyscale Platform,</span> an enterprise-ready managed Ray platform, to accelerate time-to-market.. Watch Demo"}, {"role": "assistant", "content": "https://www.youtube.com/embed/Q1t9qeDJquI"}]}
{"messages": [{"role": "user", "content": "<span class=\"text-orange\"> Ray</span> increases developer velocity and provides a unified scalable compute framework for data ingest and preprocessing, machine learning training, deep learning, hyperparameter tuning, model serving, and more, while integrating seamlessly with the  machine learning ecosystem.<br>\n<br>\n\nThe <span class=\"text-orange\"> Anyscale Platform</span> offers key advantages over Ray open source. It provides a seamless user experience for developers and AI teams to speed development, and deploy AI/ML workloads at scale. Companies using Anyscale benefit from rapid time-to-market and faster iterations across the entire AI lifecycle.\n. Download the Anyscale Platform Overview "}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/32SriyXoFAcTa8xcjGkHej/c5afbef9e487f7e4bfb7594ea097451f/Anyscale_Overview_Datasheet.pdf"}]}
{"messages": [{"role": "user", "content": ". Try It Now"}, {"role": "assistant", "content": "https://www.anyscale.com/signup"}]}
{"messages": [{"role": "user", "content": "How __Amazon__ Scales Improves Cost and Performance by 90% on Ray"}, {"role": "assistant", "content": "https://youtu.be/RNrE7B8WTCU"}]}
{"messages": [{"role": "user", "content": "How __Meta__ Scales Distributed Training of AI Workloads on Ray"}, {"role": "assistant", "content": "https://youtu.be/-fV43Bvzrso"}]}
{"messages": [{"role": "user", "content": "How __KocDigital__ Scales AI and Simplifies AI Development and Ops on Ray"}, {"role": "assistant", "content": "https://youtu.be/mt-zM9tliYo"}]}
{"messages": [{"role": "user", "content": "How __Netflix__ Scales ML Workloads and Speeds AI Innovation on Ray"}, {"role": "assistant", "content": "https://youtu.be/GtQjTWGQUHI"}]}
{"messages": [{"role": "user", "content": "Understand how Biolexis used the Anyscale fully-managed Ray platform to accelerate drug discovery by 56X, allowing the team to focus on accelerating AI-driven scientific outcomes versus investing time and effort on building AI infrastructure.. Read Now"}, {"role": "assistant", "content": "https://www.anyscale.com/blog/biolexis-boosts-their-new-ai-ml-drug-discovery-platform-using-anyscales"}]}
{"messages": [{"role": "user", "content": "<span style=\"font-size:20px;\"><span style=\"text-decoration:underline;\">[__Download Brand Guidelines__](https://assets.ctfassets.net/xjan103pcp94/54DBn9JDZo1SUQyLoFMuaI/9d13c0a2ed608c201ba6bdf13bbc8c89/Scaled_on_Ray_Branding_Guidelines__2_.pdf)</span></span>. Download Brand Guidelines"}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/54DBn9JDZo1SUQyLoFMuaI/9d13c0a2ed608c201ba6bdf13bbc8c89/Scaled_on_Ray_Branding_Guidelines__2_.pdf"}]}
{"messages": [{"role": "user", "content": "<span style=\"font-size:20px;\"><span style=\"text-decoration:underline;\">[__Download Logo Image Files__](https://assets.ctfassets.net/xjan103pcp94/6m49FIXbw671jtAejRMsQf/93713b3533681d8e9f4afcaa4dc39727/Ray_Scaled_LOGOS.zip)</span></span>. Download Logo Image Files"}, {"role": "assistant", "content": "https://assets.ctfassets.net/xjan103pcp94/6m49FIXbw671jtAejRMsQf/93713b3533681d8e9f4afcaa4dc39727/Ray_Scaled_LOGOS.zip"}]}
{"messages": [{"role": "user", "content": ". Demo Anyscale"}, {"role": "assistant", "content": "https://www.anyscale.com"}]}
{"messages": [{"role": "user", "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.. Learn More and Hear from Users"}, {"role": "assistant", "content": "https://www.anyscale.com/ray-summit-2022"}]}
{"messages": [{"role": "user", "content": ". Click for a Demo"}, {"role": "assistant", "content": "https://www.anyscale.com"}]}
{"messages": [{"role": "user", "content": ". Get the demo"}, {"role": "assistant", "content": "https://www.anyscale.com"}]}
{"messages": [{"role": "user", "content": "This is the section used to show the headline and subheading in the hero for the Capabilities landing page template.. A Possible CTA"}, {"role": "assistant", "content": "#"}]}
{"messages": [{"role": "user", "content": "Another new artificial-intelligence tool has created a firestorm on the internet: a chatbot, called ChatGPT, that provides immensely detailed, near-lifelike responses to almost any question you can imagine. But while ChatGPT and other viral tools like Prisma Labs' Lensa catch all the buzz, there's a little-known distributed framework powering this new generative-AI revolution that's flying under the radar.\n\nRay, the framework from the A16z-backed startup Anyscale, was key in enabling OpenAI to beef up its ability to train ChatGPT and models like it. Ray operates under the hood for all of OpenAI's recent large language models \u2014 and it's also the likely framework behind OpenAI's highly anticipated next act, commonly referred to as GPT-4. Industry insiders think it could create a new wave of billion-dollar businesses by generating near-human-like content.\n\nRay is already earning top marks in the field. Before deploying it, OpenAI used a hodgepodge of custom tools to develop early models and products. But as the weaknesses became more apparent, the company made the switch to using Ray, OpenAI's president, Greg Brockman, said at the Ray Summit earlier this year.\n\nLukas Biewald, the CEO of Weights & Biases, which helps companies track machine-learning experiments and is considered a hot rising star in the AI world, said his company's most forward-thinking customers loved the product \u2014 OpenAI included. This makes him think Ray is promising, he said.\n\n\"The idea that you could run the same code on your laptop and on a huge distributed set of servers is a huge deal, and the importance of it increases as models get bigger,\" Biewald told Insider. \"I think the devil is in the details, and they appear to have done a good job with them.\"\n\n__A billion-dollar bet on Ray__\nAnyscale has proved to be such a prized commodity that Ben Horowitz, of the Andreessen Horowitz and A16z namesake, is a board member. Its most recent round, an extension of its Series C that valued it at more than $1 billion, closed in a matter of days, people with knowledge of the deal said.\n\nSome investors described Anyscale as Horowitz's hopeful \"next Databricks\" \u2014 an apt description given one of the startup's founders, Ion Stoica, was a cofounder of the $31 billion data giant.\n\n\"AI is incredibly fast-moving and new approaches and people are trying new approaches all the time,\" Anyscale CEO Robert Nishihara told Insider. \"ChatGPT combined a lot of the previous work on large language models with reinforcement as well. Underlying this you need to have infrastructure that enables that flexibility and innovate quickly and scale different algorithms and approaches. A lot of the flexibility Ray provides comes from the ability to use both tasks and actors in Python.\"\n\nBecause these buzzy new tools like ChatGPT require increasingly massive models, companies have had to rethink the way they develop them from the ground up. Ray fills that gap, making it easier to train these colossal models and possible to include the hundreds of billions of data points that give every response a quasi-lifelike feel to it.\n\n__How Ray become a go-to tool for machine learning__\nRay provides an underlying infrastructure that manages the complex task of distributing the work of training a machine-learning model. Machine-learning experts can often run small models that use limited sets of data \u2014 say, a model to predict whether a customer will stop buying a product \u2014 on their own laptop. For something like ChatGPT, however, a laptop isn't going to cut it. Instead, those models require an army of servers to train their tools.\n\nBut one of the biggest challenges is to orchestrate that training across all those different pieces of hardware. Ray provides a mechanism for managing disparate pieces of hardware as a single unit for a programmer \u2014 determining what data goes where, how to handle failures, and others. Ray extends a key programming concept, \"actors,\" in other languages to Python, the language of choice for machine learning.\n\nSometimes it's not even the same hardware \u2014 and can contain a mix of products like Google Cloud, AWS, and others working on the same problem.\n\nBefore deploying Ray, OpenAI used a hodgepodge set of custom tools built on top of \"neural programmer-interpreter\" model. As the company scaled, it found itself creating new custom tweaks to its developer tools and infrastructure, said Brockman, the OpenAI president.\n\n\"It was the bare-minimum investment we could make and still not be unhappy,\" Brockman said, at the talk, about deploying NPI models. \"If something is not your core competence, you think, 'Why am I shuffling around the bits and dealing with a TCP stream with pickles in it?' That's not our burning passion.\"\n\nTapping Ray removes that immense layer of complexity, opening up more time and energy for a company like OpenAI to focus on their key competency.\n\n__A new generation of AI demands new developer tools like Ray and JAX__\nRay is just one in a series of rapidly emerging next-generation machine-learning tools that are quickly upending the way development happens. Google's JAX framework, for instance, is also gathering enormous traction. Many expect JAX to become the backbone of Google's core machine-learning tools, as it's already achieved widespread adoption in its DeepMind and Google Brain divisions.\n\nIt also isn't the only tool focused on a problem like this. Another startup backed by FirstMark Capital and Bessemer Venture Partners, Coiled, develops a framework called Dask to manage distributing this problem.\n\nAll these tools, Ray and JAX included, are in service to a new generation of combustion engines for the internet called large language models. These tools, trained on billions of data points, try to predict the structure of sentences and responses and spit out lifelike text responses to inbound queries. Multiple companies, both startups and giants, are building their own large language models including Meta, Hugging Face, OpenAI, and Google.\n\n\"It is profoundly important to understand how difficult it is to break up work (large models) and spread it across lots of little chips,\" Andrew Feldman, the CEO of the AI chip startup Cerebras Systems, told Insider. \"It's a punishingly difficult problem across the board.\"\n\n[Access the Business Insider artcle](https://www.businessinsider.com/openai-chatgpt-trained-on-anyscale-ray-generative-lifelike-ai-models-2022-12)"}, {"role": "assistant", "content": "https://www.businessinsider.com/openai-chatgpt-trained-on-anyscale-ray-generative-lifelike-ai-models-2022-12"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '5:00 p.m. Welcome remarks & upcoming announcements - Jules Damji, Anyscale\\n5:10 p.m. ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/ray-observability-present-and-future'}, 'content': [{'data': {}, 'marks': [], 'value': 'Talk 1: Observing and debugging Ray: Present and future', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '\\n6:00 p.m. Q & A\\n6:10 p.m. ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/distributed-vector-generation-in-one-step-with-ray'}, 'content': [{'data': {}, 'marks': [], 'value': 'Talk 2: Distributed Vector Generation in One Step with Ray', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '\\n6:50 p.m. Q & A', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 1: ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/ray-observability-present-and-future'}, 'content': [{'data': {}, 'marks': [], 'value': 'Observing and debugging Ray: Present and future', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '\\nAbstract: Machine Learning offline and online serving users leverage Ray in radically different ways, which makes it challenging to provide a common architecture to inspect and debug performance problems.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': \"In this talk, we discuss Ray 2. x's current observability architecture, including how to view metrics and logs and inspect the state of tasks, actors, and other resources in Ray. We discuss features like the newly revamped ray dashboard and the added ray metrics and present a roadmap for where Ray observability is going in the future with a unified observability data model.\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': \"This talk is for you if you're interested in the following:\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'What\u2019s new with ray metrics and dashboard revamp\\nHow to debug Ray programs using the CLI, Dashboard, and logs\\nlearn how to implement observability in a general-purpose distributed system such as Ray.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Bio(s):', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': \"\\nSangBin Cho is a software engineer at Anyscale and a committer on open-source Ray. He has contributed to various parts of Ray's core distributed systems, including scalable metrics infrastructure, new actor fault tolerance mechanism, placement group APIs, and stable memory management subsystems.\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': \"Ricky Xu is a software engineer working on Ray Core at Anyscale for Ray's open-source project. He graduated from Carnegie Mellon University and worked at Meta in the Core Data organization. He is passionate about building the future of distributed computing with Ray.\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Talk2: ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/distributed-vector-generation-in-one-step-with-ray'}, 'content': [{'data': {}, 'marks': [], 'value': 'Distributed Vector Generation in One Step with Ray', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '\\nAbstract: The combination of big data and deep learning has fundamentally changed how we approach data science; through machine learning models and application-specific code, computers can \" understand\" unstructured data (think images and audio). To leverage these capabilities, most applications require a continuous pipeline of one or more trained models interlinked with data processing functions. The Towhee open-source project aims to provide users with a tool to create these end-to-end pipelines using a simple API. This is done by providing generic data processing scripts, pre-trained ML models, training tools, and a Pythonic toolkit to stitch all the parts into a pipeline on a local machine. Doing this locally was hard enough, but scaling these pipelines is one step above and has remained a key challenge for us from day 1.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'This talk will discuss how integrating a Ray engine into Towhee has helped our users confidently scale their unstructured data processing pipelines and other ML applications. Using Ray as a backend, our users can easily schedule compute-heavy Towhee operations using Ray Actors found in Ray Core. First, we will discuss some challenges in building scalable machine learning pipelines. Second, we will elaborate on the pipeline development-to-deployment gap and why Ray is the obvious choice for our users and us. Finally, we will provide a live demo of a real-world data processing application scaled using Ray.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Bio', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ':\\nFilip Haltmayer is a Software Engineer at Zilliz currently working on both the open-source Towhee and Milvus projects. Along with working on developing both the core system architecture and distributed compute, he is also active in the growth of the project communities, guiding new users in deployments and creating welcoming, active environments for both projects.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}"}, {"role": "assistant", "content": "https://www.youtube.com/watch?v=N_4pg2iKgBE&list=PLzTswPQNepXl2d-dXwrCglEX9dUYLilb9"}]}
{"messages": [{"role": "user", "content": "{'nodeType': 'document', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'We are delighted to kick off New Year with our first exclusive\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'European', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0Ray Meetup with talks from Ray community Ray Serve users in Europe.\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': '(Note', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0the meetup is at', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': '\\xa05:30-PM CET/ 8:30 AM PST)', 'marks': [{'type': 'bold'}], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://docs.ray.io/en/latest/serve/index.html#serve-scalable-and-programmable-serving'}, 'content': [{'nodeType': 'text', 'value': 'Ray Serve\\xa0', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': 'is a scalable model serving library for building online inference APIs. Serve is framework agnostic, so you can use a single toolkit to serve everything from deep learning models built with frameworks like PyTorch, Tensorflow, and Keras, to Scikit-Learn models, to arbitrary Python business logic.', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://www.argilla.io/'}, 'content': [{'nodeType': 'text', 'value': 'Argilla', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '\\xa0is a production-ready framework for building and improving datasets for NLP projects. This allows you to build robust NLP products through faster data labeling and curation. Argilla.io empowers teams with the easiest-to-use human-in-the-loop and programmatic labeling features.', 'marks': [], 'data': {}}]}, {'nodeType': 'embedded-asset-block', 'data': {'target': {'sys': {'id': '3Ik8Uz5gggdFRGWG1JoiMk', 'type': 'Link', 'linkType': 'Asset'}}}, 'content': []}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Agenda: 5:30-PM CET/ 8:30 AM PST', 'marks': [{'type': 'bold'}], 'data': {}}]}, {'nodeType': 'unordered-list', 'data': {}, 'content': [{'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk - 0', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': Welcome remarks & upcoming announcements - ', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Jules Damji, Anyscale', 'marks': [{'type': 'italic'}], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk -1', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': A Brief overview of Ray Serve - ', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Jules S. Damji, Anyscale', 'marks': [{'type': 'italic'}], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk -2', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': Scaling to/from zero on demand with Serve Handle API - ', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Miha Jenko, Outbrain', 'marks': [{'type': 'italic'}], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk-3', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': Smart shortcuts for bootstrapping a modern NLP project - ', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'David Berenstein, Argilla.io', 'marks': [{'type': 'italic'}], 'data': {}}]}]}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk 1:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0:\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'A Brief overview of Ray Serve', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Abstract', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': Ray Serve lets you serve machine learning models in real-time or batch using a simple Python API. Serve individual models or create composite model pipelines, where you can independently deploy, update, and scale individual components.', 'marks': [], 'data': {}}]}, {'nodeType': 'heading-4', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/state-of-ray-serve-in-2-dot-0'}, 'content': [{'nodeType': 'text', 'value': 'View Slides', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Bio:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0 Jules S. Damji is a lead developer advocate with the Ray team at Anyscale Inc, an MLflow contributor, and co-author of', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://www.amazon.com/Learning-Spark-Jules-Damji/dp/1492050040/ref=asc_df_1492050040/?tag=hyprod-20&linkCode=df0&hvadid=459538011055&hvpos=&hvnetw=g&hvrand=7284095876924934777&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9032007&hvtargid=pla-918087322526&psc=1&asin=1492050040&revisionId=&format=4&depth=1'}, 'content': [{'nodeType': 'text', 'value': 'Learning Spark, 2nd Edition', 'marks': [{'type': 'underline'}, {'type': 'italic'}], 'data': {}}, {'nodeType': 'text', 'value': '.', 'marks': [{'type': 'underline'}], 'data': {}}]}, {'nodeType': 'text', 'value': ' He is a hands-on developer with over 25 years of experience. He has worked at leading companies, such as Sun Microsystems, Netscape, @Home, Opsware/LoudCloud, VeriSign, ProQuest, Hortonworks, and Databricks, building large-scale distributed systems. He holds a B.Sc and M.Sc in computer science (from Oregon State University and Cal State, Chico, respectively) and an MA in political advocacy and communication (from Johns Hopkins University).', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk 2:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Scaling to/from zero on demand with Serve Handle API', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Abstract', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': In this talk, we will discuss an implementation of a REST API controller for on-demand scaling of Serve replicas. This process updates Serve Deployment configurations, similarly to the Serve REST API, which has been available since Ray 2.0.0. We will also cover the use case and motivations for this approach, as well as our experience with the Ray developer community.', 'marks': [], 'data': {}}]}, {'nodeType': 'heading-4', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/from-zero-on-demand-with-serve-handle-api'}, 'content': [{'nodeType': 'text', 'value': 'View Slides', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Bio:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0Miha Jenko recently joined Outbrain as a data scientist. At his previous employer, he discovered a need for optimizing content management processes specific to e-commerce. This led him to gain experience in implementing various MLOps patterns.', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Talk 3', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ':\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Smart shortcuts for bootstrapping a modern NLP project', 'marks': [{'type': 'bold'}], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Abstract:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0Within NLP, people often struggled with starting projects without decent training data. Nowadays, there are many shortcuts that one can use to get a head start with projects like these by applying techniques such as active learning, weak supervision, few-shot learning, and cross-lingual models. I will show you how to use them and make them work even better using Ray!', 'marks': [], 'data': {}}]}, {'nodeType': 'heading-4', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/smart-shortcuts-for-bootstrapping-a-modern-nlp-project'}, 'content': [{'nodeType': 'text', 'value': 'View Slides', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Bio:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0David Berenstein joined Argilla as a developer advocate after having worked on some\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://github.com/Pandora-Intelligence'}, 'content': [{'nodeType': 'text', 'value': 'NLP-related open-source side-projects', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '\\xa0at his previous company. I love making things work as pragmatic as possible given the available resources.', 'marks': [], 'data': {}}]}, {'nodeType': 'heading-2', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://youtu.be/tdGvtMv8IiE'}, 'content': [{'nodeType': 'text', 'value': 'Watch Video', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}]}. Watch video"}, {"role": "assistant", "content": "https://youtu.be/tdGvtMv8IiE"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Agenda:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': '5:00 p.m.', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/ray-community-meetup-jan-25-2023'}, 'content': [{'data': {}, 'marks': [], 'value': 'Welcome remarks, Year 2022: Ray in Review & upcoming announcements', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ' -\\xa0', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'italic'}], 'value': 'Jules Damji, Anyscale', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 1 (35-40 mins):', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/ray-community-meetup-jan-25-2023-ray-oom-monitor'}, 'content': [{'data': {}, 'marks': [], 'value': 'Monitor & prevent out-of-memory problems with Ray OOM monitor', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ' -\\xa0', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'italic'}], 'value': 'Clarence Ng, Anyscale', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Q & A (10 mins)', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 2 (35-40 mins):', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/how-shopify-used-ray-tensorflow-to-build-a-product-hierarchical-categorization-model-to-auto-classify-billions-of-products-using-nlp-and-computer-vision'}, 'content': [{'data': {}, 'marks': [], 'value': 'How Shopify used Ray<>Tensorflow to build a Product Hierarchical Categorization model to auto classify billions of products using NLP and Computer ', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': 'Vision,\\xa0', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'italic'}], 'value': 'Kshetrajna Raghavan, Shopify', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Q & A (10 mins)', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 1 :', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0Monitor & prevent out-of-memory problems with Ray OOM monitor\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Abstract:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0It is often difficult to predict or estimate the memory usage of a Ray program. This is often key for data ingestion or processing as it impacts the performance and stability of the training task. In the mild case the program slows down, and in the worse case it fails, incurring cost and wasted time.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Since the release of Ray 2.0 we have significantly improved the stability of the system. One such improvement is the handling of out-of-memory (OOM) issues triggered by the program. In this talk, we discuss the architecture of the OOM monitor, how to debug OOM using the latest observability tools, and a sneak peak of the upcoming change to the algorithm that will make the Ray more resilient to OOM issues.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': \"This talk is for you if you're interested in:\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'How to debug Ray program that is suffering from OOM issues', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'How to configure the OOM monitor', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'The internals of the OOM monitor and how it interacts with some of the common workloads', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'unordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Bio:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0Clarence Ng is a software engineer at Anyscale. He has experience building large scale distributed systems at places such as Amazon and Google, where he built ML ingestion pipelines, database service, cluster manager, and object storage service. He has contributed to the memory management subsystem for Ray.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 2:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0How Shopify used Ray<>Tensorflow to build a Product Hierarchical Categorization model to auto classify billions of products using NLP and Computer Vision\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Abstract:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\nOrganizing products using structured metadata is crucial in online retail. This metadata is usually needed by many downstream applications including search and discovery, trust and safety, analytics and reporting among others. At Shopify we like to make the commerce journey as easy as possible for our merchants and one part of this is using Machine Learning to predict the product category for the billions of products that our merchants sell.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'We will look at how we solved this problem using transfer learning through Natural Language Processing and Computer vision to create a hierarchical classification Deep Neural Network to categorize products into a hierarchical tree taxonomy. We will dig deeper into modeling challenges and how we came up with specific architecture decisions. We will then dive into how Ray and other tool choices made this work at Shopify Scale. The talk will cover how we continuously monitor the performance of the model using both ML as well as business metrics and how this leads into a feedback mechanism that results in better models.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Finally we will talk about how all of this was built keeping merchant success front and center of all the product as well as technical decisions we made by talking about different features that are built on top of this model that have benefited our merchants.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Bio:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\xa0Kshetrajna is a Staff Data Scientist at Shopify working on the capital algorithms team. He has built and productionalized many models in various domains including retail, ad-tech and healthcare. His interests are mainly applied ML and ML systems and enjoys solving complex problems to help use machine learning at scale. Outside of work, Kshetrajna loves to spend time with his dogs, play music on his guitar, and is an avid gamer.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://youtu.be/kYfupnqGd-0'}, 'content': [{'data': {}, 'marks': [], 'value': 'Watch video', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'heading-3'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch Video"}, {"role": "assistant", "content": "https://youtu.be/kYfupnqGd-0"}]}
{"messages": [{"role": "user", "content": "{'nodeType': 'document', 'data': {}, 'content': [{'nodeType': 'heading-2', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Details', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'For those in the\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'EDT', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0timezone, this is a joint meetup with\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://www.meetup.com/nyc-machine-learning-ai/events/291605712/'}, 'content': [{'nodeType': 'text', 'value': 'NYC ML/AI meetup\\xa0', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': 'for you. Join us if you are an ML practitioner and want to learn how you can:', 'marks': [], 'data': {}}]}, {'nodeType': 'unordered-list', 'data': {}, 'content': [{'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Crunch timeseries and forecasting data at massive scale with ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://www.ray.io/'}, 'content': [{'nodeType': 'text', 'value': 'Ray', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': ' from ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://www.nixtla.io/'}, 'content': [{'nodeType': 'text', 'value': 'Nixtla', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Conduct distributed data processing with Python ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://getdaft.io/'}, 'content': [{'nodeType': 'text', 'value': 'Daft Dataframes\\xa0', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': ' using Ray as its distributed compute engine.', 'marks': [], 'data': {}}]}]}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Both are exclusive Ray community user talks, and the Ray team is delighted to have them share their Ray use cases and journeys with the community.', 'marks': [], 'data': {}}]}, {'nodeType': 'embedded-asset-block', 'data': {'target': {'sys': {'id': '10Rutnw3EM5mBDNOUoCmb6', 'type': 'Link', 'linkType': 'Asset'}}}, 'content': []}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Agenda', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n(The times are not strict; they may vary slightly.)\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Talk 0', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/ai-meetup-community-talks-march-22-2023?slide=10'}, 'content': [{'nodeType': 'text', 'value': 'Welcome remarks & upcoming Ray announcements', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': ' -\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Jules Damji, Anyscale', 'marks': [{'type': 'italic'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Talk 1 (30-35 mins):', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0Forecasting at Scale with ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://www.nixtla.io/'}, 'content': [{'nodeType': 'text', 'value': 'Nixtla and Ray\\xa0', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '-', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Max Mergenthaler & Frderico Ramirez, Nixtla', 'marks': [{'type': 'italic'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Talk 2 (30-35 mins) :', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/daft-pyton-distributed-dataframe-for-complex-data'}, 'content': [{'nodeType': 'text', 'value': 'Daft: The Ray-native Python dataframe for Complex Data', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': ' -\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Jay Chia, Eventual', 'marks': [{'type': 'italic'}], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk1 : Forecasting at Scale with Nixtla and Ray', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Abstract', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': Forecasting and anomaly detection at scale is important for various industries, including financial services, CPG/retail, and IOT/operational ML. Ray and Nixtla offer a robust open-source solution for processing time series at scale.The meetup talk will cover best practices for working with time series data, various time series modeling techniques, and how Anyscale can handle training millions of time series models efficiently.', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Bio(s)', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ':\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Max', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': \"\\xa0is the CEO and Co-Founder of Nixtla, an open-source time-series research and deployment startup. He is also a seasoned entrepreneur with a proven track record as the founder of multiple technology startups. With a decade of experience in the ML industry, he has extensive expertise in building and leading international data teams. Max has also made notable contributions to the Data Science field through his co-authorship of papers on forecasting algorithms and decision theory. In addition, he is a co-maintainer of several open-source libraries in the Python ecosystem. He has been a speaker at major data conferences in different countries. Max's passion lies at the intersection of business and technology.\", 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Fede', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': \"\\xa0is a highly experienced ML engineer, with a background in economics and mathematics. They is CTO and co-founder of Nixtla. With over a decade of expertise in deploying ML models in production for large financial institutions, Fede has a proven track record of delivering end to end products. They are passionate about creating usable, scalable, and open-source ML products, and are a co-maintainer of several popular Python libraries. Fede's expertise in the field has also earned them recognition as a speaker at multiple Pycons and author of peer reviewed papers, solidifying their status as a leading expert in time series analysis.\", 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk 2:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Daft:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'T', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://www.getdaft.io/'}, 'content': [{'nodeType': 'text', 'value': 'he Ray-native Python dataframe for Complex Data', 'marks': [{'type': 'bold'}], 'data': {}}]}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Abstract', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': ': Modern machine learning is data-driven, however working interactively with \u201cComplex Data\u201d (data that doesn\\'t usually fit in a SQL table such as images, videos, documents etc) is still extremely challenging.Daft is an open-sourced distributed dataframe library built for \"Complex Data\" . It provides a familiar dataframe tabular interface (similar to Pandas or PySpark) over your data, and its native integrations with Ray allow it to scale to terabytes of data on workloads such as: interactive SQL-like queries, running models on GPUs and interactive data exploration.In this meetup talk, we demo an interactive exploration of the Coco image dataset. We will then make use of Daft\u2019s Ray Dataset integrations to train your models - all happening end-to-end out-of-core and streaming on the same Ray cluster!', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Bio:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0Jay Chai is co-founder of Eventual, the company behind Daft (', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'http://www.getdaft.io/'}, 'content': [{'nodeType': 'text', 'value': 'www.getdaft.io', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '). He has worked in ML/data infrastructure in domains such as genomics and self-driving. He is frustrated that tabular data is so easy to work with using SQL and wishes that the same can exist for Complex Data!', 'marks': [], 'data': {}}]}, {'nodeType': 'heading-2', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://youtu.be/1MpEYlIlu7w?list=PLzTswPQNepXl2d-dXwrCglEX9dUYLilb9'}, 'content': [{'nodeType': 'text', 'value': 'Watch the Video', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'heading-2', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/ai-meetup-community-talks-march-22-2023?slide=10'}, 'content': [{'nodeType': 'text', 'value': 'Talk 0: Slides', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'heading-2', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/daft-pyton-distributed-dataframe-for-complex-data'}, 'content': [{'nodeType': 'text', 'value': 'Talk 2: Slides', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}]}. Watch Video"}, {"role": "assistant", "content": "https://youtu.be/1MpEYlIlu7w?list=PLzTswPQNepXl2d-dXwrCglEX9dUYLilb9"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://siliconangle.com/2023/03/02/rise-ai-anyscale-works-simplify-ai-workloads-open-source-project-awsshowcases3e1/'}, 'content': [{'data': {}, 'marks': [], 'value': 'Read the article', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Watch now"}, {"role": "assistant", "content": "https://siliconangle.com/2023/03/02/rise-ai-anyscale-works-simplify-ai-workloads-open-source-project-awsshowcases3e1/"}]}
{"messages": [{"role": "user", "content": "{'nodeType': 'document', 'data': {}, 'content': [{'nodeType': 'embedded-asset-block', 'data': {'target': {'sys': {'id': '5vB7rvg7dwN7owoGjUDJPz', 'type': 'Link', 'linkType': 'Asset'}}}, 'content': []}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'This month we had two Ray committers and a Pinterest community Ray user to share with the community:', 'marks': [], 'data': {}}]}, {'nodeType': 'unordered-list', 'data': {}, 'content': [{'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'How to use Ray for batch inference at scale, comparing solutions against other alternatives such as Apache Spark and SageMaker.', 'marks': [], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'How Ray Data streaming can be used to further optimize hardware accelerators (CPUs and GPUs) for parallel pipeline execution.', 'marks': [], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'How Ray is used at Pinterest for workflow-oriented ML development', 'marks': [], 'data': {}}]}]}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'The slides and video are below \ud83d\udc47, scroll to the end.', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Agenda', 'marks': [{'type': 'bold'}], 'data': {}}]}, {'nodeType': 'unordered-list', 'data': {}, 'content': [{'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '5:30-6:00 pm :', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': 'Networking, Snacks & Drinks', 'marks': [], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '6:00 pm: Talk 1 (30-35 mins): ', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': 'Offline Batch Inference: Comparing Ray, Apache Spark, SageMaker - ', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Amog Kamsetty Anyscale', 'marks': [{'type': 'italic'}], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Q & A (10 mins)', 'marks': [{'type': 'bold'}], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '6:35 pm: Talk 2 (30-35 mins): ', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': 'Streaming distributed execution across CPUs and GPUs -', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Eric Liang, Anyscale', 'marks': [{'type': 'italic'}], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Q & A (10 mins)', 'marks': [{'type': 'bold'}], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '7:10 pm:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Talk 3', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': '30-35 mins): ', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': 'Workflows to interactive pipelines: How Pinterest plans to improve ML developer velocity with Ray - ', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Se Won Jang, Pinterest', 'marks': [{'type': 'italic'}], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Q & A (10 mins)', 'marks': [{'type': 'bold'}], 'data': {}}]}]}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk 1: Offline Batch Inference: Comparing Ray, Apache Spark, and SageMaker', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Abstract:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0As more companies use large scale machine learning (ML) models for training and evaluation, offline batch inference becomes an essential workload. A number of challenges come with it: managing compute infrastructure; optimizing use of all heterogeneous resources; and transferring data from storage to hardware accelerators. Addressing these challenges, Ray performs significantly better as it can coordinate clusters of diverse resources, allowing for better utilization of the specific resource requirements of the workload.', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'In this talk we will talk about:', 'marks': [], 'data': {}}]}, {'nodeType': 'unordered-list', 'data': {}, 'content': [{'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'What are the challenges and limitations', 'marks': [], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Examine three different solutions for offline batch inference: AWS SageMaker Batch Transform, Apache Spark, and Ray Data.', 'marks': [], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Share our performance numbers showing Ray data as the best solution for offline batch inference at scale', 'marks': [], 'data': {}}]}]}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Bio:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': \"\\xa0Amog Kamsetty is a software engineer at Anyscale where he works on building distributed ML libraries and integrations on top of Ray. He is one of the lead developers of Ray's distributed training and offline batch inference libraries.\", 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk 2: Streaming distributed execution across. CPUs and GPUs', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Abstract:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0Some of the most demanding machine learning (ML) use cases we have encountered involve pipelines that span both CPU and GPU devices in distributed environments. These situations are common workloads, including:', 'marks': [], 'data': {}}]}, {'nodeType': 'unordered-list', 'data': {}, 'content': [{'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Batch inference, which involves a CPU-intensive preprocessing stage (e.g., video decoding or image resizing) before utilizing a GPU-intensive model to make predictions.', 'marks': [], 'data': {}}]}]}, {'nodeType': 'list-item', 'data': {}, 'content': [{'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Distributed training, where similar CPU-heavy transformations are required to prepare or augment the dataset prior to GPU training.', 'marks': [], 'data': {}}]}]}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'In this talk, we examine how Ray data streaming works and how to use it for your own machine learning pipelines to address these common workloads utilizing all your compute resource\u2013CPUs and GPUs\u2013at scale.', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Bio:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0Eric Liang is a software engineer at Anyscale and TL for the Ray open source project. He is interested in building reliable and performant distributed systems. Before joining Anyscale, Eric was a staff engineer at Databricks, and received his PhD from UC Berkeley.', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Talk 3:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Workflows to interactive pipelines: How Pinterest plans to improve ML developer velocity with Ray', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\n', 'marks': [], 'data': {}}, {'nodeType': 'text', 'value': 'Abstract:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0Large scale machine learning at web scale companies often involve a long chain of big-data processing, training, and evaluation jobs expressed as workflows. ML application and platform teams invest in making these workflows easier to compose, reproduce, and production ready. However, workflow-based developer experiences have inherent limitations when it comes to quickly iterating on new ideas - In many cases, jobs have to be written, tested and integrated carefully before a hypothesis can be tested.', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'In this talk, we will discuss how Pinterest plans on shifting this workflow-oriented ML development paradigm using Ray, into one that empowers interactive and fast iteration while ensuring production readiness. We will visit various investments Pinterest made to streamline workflow-oriented ML development, common usage patterns, and where we envision ourselves in the next 12 months with Ray', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Bio:', 'marks': [{'type': 'bold'}], 'data': {}}, {'nodeType': 'text', 'value': '\\xa0', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://www.linkedin.com/in/se-won-jang-0b5a6265/'}, 'content': [{'nodeType': 'text', 'value': 'Se Won Jang i', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': 's the engineering manager of the ML Data Platform team at Pinterest. Before this role, he was the tech-lead of the feature store, dataset management, and training orchestration initiatives at Pinterest.', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Watch: ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://youtu.be/RY02VBJBIm0?t=989'}, 'content': [{'nodeType': 'text', 'value': 'MEETUP VIDEO', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Slides: ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/bay-area-ray-june-meetup-community-talks'}, 'content': [{'nodeType': 'text', 'value': 'Introduction Talk', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Slides: ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/offline-batch-inference-comparing-ray-apache-spark-sagemaker'}, 'content': [{'nodeType': 'text', 'value': 'Batch Inference Talk', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}, {'nodeType': 'paragraph', 'data': {}, 'content': [{'nodeType': 'text', 'value': 'Slides: ', 'marks': [], 'data': {}}, {'nodeType': 'hyperlink', 'data': {'uri': 'https://speakerdeck.com/anyscale/streaming-distributed-execution-across-cpus-and-gpus'}, 'content': [{'nodeType': 'text', 'value': 'Streaming Distributed Execution Talk', 'marks': [], 'data': {}}]}, {'nodeType': 'text', 'value': '', 'marks': [], 'data': {}}]}]}. WATCH THE VIDEO"}, {"role": "assistant", "content": "https://youtu.be/RY02VBJBIm0?t=989"}]}
{"messages": [{"role": "user", "content": "Everything you need to select, integrate, and deploy an LLM\n- Built on Ray Serve, Anyscale\u2019s proven and popular open source library for model serving\n- Offers Interactive front-end to submit prompts and evaluate responses\n- Delivers fault tolerance, dynamic model deployment, and request batching\n- Includes all Libraries, open source models, examples and code\n. Try LLMs with Aviary Explorer"}, {"role": "assistant", "content": "https://aviary.anyscale.com"}]}
{"messages": [{"role": "user", "content": "- Reduces costs significantly using spot instances with on-demand fallback\n- Enables zero-downtime upgrades with no dropped requests\n- Delivers faster deployment and autoscaling\n- Includes improved observability tools\n. Request a Trial of Aviary on Anyscale"}, {"role": "assistant", "content": "https://4ml215gnt0m.typeform.com/to/yjRbClLv"}]}
{"messages": [{"role": "user", "content": "\nBuilt on Ray Serve, Anyscale\u2019s proven and popular open source library for model serving<br /><br />\nOffers Interactive front-end to submit prompts and evaluate responses <br /><br />\nDelivers fault tolerance, dynamic model deployment, and request batching <br /><br />\nIncludes all Libraries, open source models, examples and code<br /><br />\n\n<a href=\"https://github.com/ray-project/aviary\">__Learn More__ </a>\n. Check out Aviary Open Source"}, {"role": "assistant", "content": "https://aviary.anyscale.com"}]}
{"messages": [{"role": "user", "content": "Reduces costs significantly using spot instances with on-demand fallback<br/><br/>\nEnables zero downtime upgrades with no dropped requests<br/><br/>\nDelivers faster deployment and autoscaling<br/><br/>\nIncludes improved observability tools<br/><br/>\n\n<a href=\"http://bit.ly/run-aviary\">__Request a Trial*__ </a>\n. Request a Trial - Aviary on Anyscale"}, {"role": "assistant", "content": "https://4ml215gnt0m.typeform.com/to/yjRbClLv"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {'target': {'sys': {'id': '5LMB9W4jsUL2ACAs6I41aX', 'type': 'Link', 'linkType': 'Asset'}}}, 'content': [], 'nodeType': 'embedded-asset-block'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'As companies and enthusiasts release new LLM-based apps almost every day, there is a growing demand for techniques, tools, and best practices related to evaluating and productionizing open-source models.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '\\u200bJoin us for a technical meetup featuring fast-paced talks presented by industry leaders, including Harrison Chase from LangChain, Robert Nishihara from Anyscale, and Michel Tricot from Airbyte.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '\\u200bModerated by the renowned deep learning educator Charles Frye, this meetup provides a unique opportunity to engage with industry leaders and learn about cutting-edge techniques and tools.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': \"\\u200bFollowing the talks, all the speakers will participate in a panel discussion. Don't forget to ask your questions to the panel! This dynamic exchange will focus on emerging trends in productionizing open-source LLMs.\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '\\u200bWe ensure ample networking opportunities for you to connect with fellow industry professionals, researchers, and enthusiasts.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '\\u200bAgenda:\\n\\u200b5:30 - 6:00 - open doors, refreshments, networking\\n\\u200b6:00 - 6:45 - 10 minute talks\\n\\u200b  Moderator: Charles Frye (Full Stack Deep Learning) - deep learning     educator\\n  \\u200bHarrison Chase (CEO, LangChain) - Evaluating LLM Applications\\n  \\u200bRobert Nishihara (CEO, Anyscale) - Scaling and Productionizing LLMs\\n  \\u200bLianmin Zheng (UC Berkeley) - Vicuna and Chatbot Arena\\n  \\u200bMichel Tricot  (CEO, Airbyte) - [tbd]\\n\\u200b6:45 -7:30 - 45 minutes panel moderated by Charles Frye\\n\\u200b7:30 - 8:30 - more refreshments and networking', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Save your spot!"}, {"role": "assistant", "content": "https://lu.ma/llmswithRayandLangChain"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {'target': {'sys': {'id': '6zm9MLefJJSLKqGaYnNjWU', 'type': 'Link', 'linkType': 'Asset'}}}, 'content': [], 'nodeType': 'embedded-asset-block'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'LLMs have gained immense popularity in recent months. An entirely new ecosystem of pre-trained models and tools has emerged that streamline the process of building LLM-based applications.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Join us for this ', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'in-person workshop in San Francisco, CA', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ' to experience building scalable LLM-based applications hands-on! Coffee and snacks included.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Key Takeaways', 'nodeType': 'text'}], 'nodeType': 'heading-2'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Use libraries like Ray, HuggingFace, and LangChain to build LLM-based applications based on open-source code, models, and data.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Learn about scaling LLM fine-tuning and inference, along with trade-offs.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Use embedding models and vector stores.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Learn about using modern deployment tools to run your application online and continually improve it.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'ordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Audience', 'nodeType': 'text'}], 'nodeType': 'heading-2'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'This workshop is for LLM-based application builders as well as ML practitioners interested in how to build LLM-based applications using open source tools.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Basic understanding of emerging LLM trends is not necessary, but will help get more out of the workshop. ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://huyenchip.com/2023/04/11/llm-engineering.html'}, 'content': [{'data': {}, 'marks': [], 'value': 'This', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': ' and ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}, {'data': {'uri': 'https://medium.com/@brian_90925/llms-and-the-emerging-ml-tech-stack-6fa66ee4561a'}, 'content': [{'data': {}, 'marks': [], 'value': 'this', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': ' blog posts are helpful background material.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'ordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Resources', 'nodeType': 'text'}], 'nodeType': 'heading-2'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'GitHub repository with relevant resources including notebooks, setup instructions, bonus resources, and a README for an overview.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Access to the GPU-based compute cluster for the duration of the training to leverage the full potential of LLMs.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Exclusive only to the workshop participants: office hours the week after the workshop for deeper discussion of the individual application ideas.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'ordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Register here:"}, {"role": "assistant", "content": "https://home.mlops.community/public/events/llm-in-prod-part-ii-2023-06-20?autoRsvp=true"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {'target': {'sys': {'id': '38LzbJpJXrBPmlMvCkoTY6', 'type': 'Link', 'linkType': 'Asset'}}}, 'content': [], 'nodeType': 'embedded-asset-block'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Meet us at booth #44! ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Learn more here!"}, {"role": "assistant", "content": "https://www.databricks.com/dataaisummit/"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {'target': {'sys': {'id': '5x4H7PsitvZy0ICtmF021J', 'type': 'Link', 'linkType': 'Asset'}}}, 'content': [], 'nodeType': 'embedded-asset-block'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Start:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ' \\nMonday, September 18 @ 8:30am\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': '\\nEnd:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ' \\nWednesday, September 20 @ 2pm\\n\\n', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'bold'}], 'value': 'About Event', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n\\nRay Summit is the conference for everything AI and more on Ray \u2014 and that means the Ray community is front and center. Every year, thousands of Ray fans come together at Ray Summit to learn, explore, and celebrate the efforts of the entire Ray community.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'The agenda for this year\u2019s Ray Summit is officially live! Discover how Ray is paving the way forward in new and thrilling AI and ML applications, with exclusive insights from industry leaders at Cohere, LinkedIn, Spotify, Amazon, DoorDash, and more. Dive into all aspects of AI and beyond, from developer-focused sessions on generative AI, to practical Ray deployment strategies for building scalable machine learning platforms and LLMs.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Ray Summit attendees are a mix of engineers and ML practitioners, developers, data scientists, and students and academics. No matter who you are, if you\u2019re passionate about Ray, distributed systems, scalable AI or LLMs, you\u2019ll find something to interest you at Ray Summit.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Come connect with the global community of thinkers and disruptors who are building and deploying the next generation of AI and ML applications.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Click\\xa0', 'nodeType': 'text'}, {'data': {'uri': 'https://raysummit.anyscale.com/?utm_source=anyscale&utm_medium=website&utm_campaign=ray_summit_2023&utm_content=featured-events-graphic'}, 'content': [{'data': {}, 'marks': [], 'value': 'here', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '\\xa0to find out more and to see the agenda and full speaker list, then take a minute to ', 'nodeType': 'text'}, {'data': {'uri': 'https://raysummit.anyscale.com/?utm_source=anyscale&utm_medium=website&utm_campaign=ray_summit_2023&utm_content=featured-events-graphic'}, 'content': [{'data': {}, 'marks': [], 'value': 'register now', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Learn more"}, {"role": "assistant", "content": "https://raysummit.anyscale.com/?utm_source=anyscale&utm_medium=website&utm_campaign=ray_summit_2023&utm_content=featured-events-graphic"}]}
{"messages": [{"role": "user", "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Mauris sollicitudin lacus hendrerit, sodales velit id, ornare ex.. Sign up "}, {"role": "assistant", "content": "https://www.ray.io/"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Please join us for an evening of technical talks on Large Language Models (LLMs) ', 'nodeType': 'text'}, {'data': {'uri': 'https://www.anyscale.com/blog/continuous-batching-llm-inference'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}], 'value': 'inference with continuous batching', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ' and ', 'nodeType': 'text'}, {'data': {'uri': 'https://aviary.anyscale.com/'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}], 'value': 'Aviary LLM Explorer', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ', an open-source hosted service for exploring LLMs, including the latest ', 'nodeType': 'text'}, {'data': {'uri': 'https://about.fb.com/news/2023/07/llama-2/'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}], 'value': 'Llama2', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ', ', 'nodeType': 'text'}, {'data': {'uri': 'https://falconllm.tii.ae/'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}], 'value': 'Falcon', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ', ', 'nodeType': 'text'}, {'data': {'uri': 'https://lmsys.org/blog/2023-03-30-vicuna/'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}], 'value': 'Vicuna', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ', and ', 'nodeType': 'text'}, {'data': {'uri': 'https://huggingface.co/mosaicml/mpt-30b'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}], 'value': 'MosaicML MPT', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ' model series.\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Also, we\u2019ll share the latest feature-updates to Aviary LLM explorer and show ', 'nodeType': 'text'}, {'data': {'uri': 'https://www.anyscale.com/'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}], 'value': 'Anyscale', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ' open source', 'nodeType': 'text'}, {'data': {'uri': 'https://console.endpoints.anyscale.com/welcome'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}], 'value': ' LLM endpoint offerings.', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ' And of course some surprise giveaways!', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'PLEASE RSVP/REGISTER FOR THIS MEETUP AT THIS LINK: ', 'nodeType': 'text'}, {'data': {'uri': 'https://lu.ma/bayarearayllmscommunitytalks'}, 'content': [{'data': {}, 'marks': [{'type': 'underline'}, {'type': 'bold'}], 'value': 'https://lu.ma/bayarearayllmscommunitytalks', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'The slides for the sessions are ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '1. ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/ray-community-llm-august-meetup'}, 'content': [{'data': {}, 'marks': [], 'value': 'Announcements', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '2. ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/how-continuous-batching-enables-23x-throughput-in-llm-inference'}, 'content': [{'data': {}, 'marks': [], 'value': 'Talk 1', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': '3. ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/5-painful-lessons-using-llms'}, 'content': [{'data': {}, 'marks': [], 'value': 'Talk 2', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {'target': {'sys': {'id': '1EzZwULHDXTZhqu0XMWfnH', 'type': 'Link', 'linkType': 'Asset'}}}, 'content': [], 'nodeType': 'embedded-asset-block'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Agenda', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': '\\n(The times are not strict; they may vary slightly.)', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': '5:30-6:00 pm', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ': Networking, Snacks & Drinks', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': '6:00 pm:', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ' Talk 1 (30-35 mins): ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/how-continuous-batching-enables-23x-throughput-in-llm-inference'}, 'content': [{'data': {}, 'marks': [], 'value': '- How continuous batching enables 23x throughput in LLM inference\\xa0', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': ' \u2013 ', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'italic'}], 'value': 'Cade Daniel, Anyscale', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Q & A (10 mins)', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': '6:45 pm', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ': Talk 2 (30-35 mins) : ', 'nodeType': 'text'}, {'data': {'uri': 'https://speakerdeck.com/anyscale/5-painful-lessons-using-llms'}, 'content': [{'data': {}, 'marks': [], 'value': '5 useful design patterns for production LLM applications ', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '- ', 'nodeType': 'text'}, {'data': {}, 'marks': [{'type': 'italic'}], 'value': 'Waleed Kadous, Anyscale', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}, {'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'Q & A (10 mins)', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'list-item'}], 'nodeType': 'unordered-list'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 1: How continuous batching enables 23x throughput in LLM inference\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Abstract', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ': Due to the large GPU memory footprint and compute cost of LLMs, serving dominates the compute cost for most real world applications. ML engineers often treat LLMs like \"black boxes\" that can only be optimized with internal changes such as quantization and custom CUDA kernels. However, this is not entirely the case. Because LLMs iteratively generate their output, and because LLM inference is often memory and not compute bound, there are surprising system-level batching optimizations that make 10x or more differences in real-world workloads.', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [], 'value': 'One recent such proposed optimization is continuous batching. In this talk we\u2019ll discuss what it is, how it works, and how it enables a 23x improvement in throughput over naive HuggingFace transformers on a production workload (3x over previous SOTA).', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Bio', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': \": Cade Daniel is a software engineer at Anyscale working on Ray and LLMs. Previously, he helped build the communication engine for training large language models using AWS SageMaker's model parallelism library. Outside of work, he enjoys sipping a good latte while liking hot takes on ML/AI Twitter.\", 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Talk 2: 5 useful design patterns for production LLM Applications', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Abstract', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ': Over the last year at Anyscale, we\u2019ve built a number of our own LLM Applications as well as helping our customers build them as well. Through that process we\u2019ve come up with 5 design patterns or principles that we feel significantly increase the chances of success in building LLM applications. We discuss those 5 patterns and how to build them into your application. It will address:\\xa0\\n1. What exactly is an LLM application is.\\n2. How to design for easy evaluation and testability.\\n3. Making LLM components reusable across applications. ', 'nodeType': 'text'}], 'nodeType': 'paragraph'}, {'data': {}, 'content': [{'data': {}, 'marks': [{'type': 'bold'}], 'value': 'Bio', 'nodeType': 'text'}, {'data': {}, 'marks': [], 'value': ': Dr. Waleed Kadous is the Chief Data Scientist at Anyscale, the company behind the popular open source project Ray. Prior to Anyscale, Waleed worked at Uber, where he led overall system architecture, evangelized machine learning, and led the Location and Maps teams. He previously worked at Google, where he founded the Android Location and Sensing team, responsible for the \u201cblue dot\u201d as well as ML algorithms underlying products like Google Fit. He also holds more than 40 patents.\\xa0', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. PLEASE RSVP/REGISTER FOR THIS MEETUP AT THIS LINK"}, {"role": "assistant", "content": "https://lu.ma/bayarearayllmscommunitytalks"}]}
{"messages": [{"role": "user", "content": "{'data': {}, 'content': [{'data': {}, 'content': [{'data': {}, 'marks': [], 'value': \"Join us for an exciting livestream hosted by Pinecone and Anyscale, the company behind Ray. This webinar will explore how developers can build a secure and scalable question-answering system on Amazon Web Services (AWS) using open-source LLMs, specifically LangChain, Anyscale, and Pinecone.\\n\\nLearn how to effortlessly harness the built-in integration between LangChain, Anyscale, and Pinecone to build AI applications on AWS. Discover how these powerful tools work together to enhance the efficiency and effectiveness of your Q&A system, enabling you to create a well-architected LLM application.\\n\\nEnhancing answer reliability is crucial, and we will show you how to leverage Pinecone's long-term memory capabilities to mitigate hallucination and ground your answers in factual information. You can significantly improve reliability and accuracy by incorporating long-term memory into your Q&A system.\\n\\nGain valuable insights into designing a well-architected LLM application on AWS. Explore best practices for optimizing performance, security, and scalability, and learn how to build an enterprise-grade Q&A system that can scale effortlessly.\\n\\n\", 'nodeType': 'text'}, {'data': {'uri': 'https://pinecone-io.zoom.us/webinar/register/WN_Qiz5ebqIQgejcK9CJ_S5kg#/registration'}, 'content': [{'data': {}, 'marks': [], 'value': 'REGISTER NOW', 'nodeType': 'text'}], 'nodeType': 'hyperlink'}, {'data': {}, 'marks': [], 'value': '', 'nodeType': 'text'}], 'nodeType': 'paragraph'}], 'nodeType': 'document'}. Register now"}, {"role": "assistant", "content": "https://pinecone-io.zoom.us/webinar/register/WN_Qiz5ebqIQgejcK9CJ_S5kg#/registration"}]}
{"messages": [{"role": "user", "content": "Ray is the most popular open source framework for scaling and productionizing AI workloads. From __Generative AI__ and __LLMs__ to computer vision, Ray powers the world\u2019s most ambitious AI workloads.. Try Llama-2"}, {"role": "assistant", "content": "https://app.endpoints.anyscale.com/landing"}]}
{"messages": [{"role": "user", "content": "Anyscale Launches New Service Anyscale Endpoints, 10X More Cost-Effective. Read it Now"}, {"role": "assistant", "content": "https://www.anyscale.com/anyscale-launches-new-service-anyscale-endpoints-10x-more-cost-effective-for-most-popular-open-source-llms"}]}
{"messages": [{"role": "user", "content": "Learning Ray: The ultimate book about Ray and its expanding ecosystem. Download Now"}, {"role": "assistant", "content": "https://www.anyscale.com/asset/book-learning-ray-oreilly"}]}
{"messages": [{"role": "user", "content": "Anyscale Teams With NVIDIA to Supercharge LLM Performance and Efficiency. Read it Now"}, {"role": "assistant", "content": "https://www.anyscale.com/anyscale-teams-with-nvidia-to-supercharge-llm-performance-and-efficiency"}]}
{"messages": [{"role": "user", "content": "Want to add an open source LLM to your app? __Get started with Llama-2 in minutes.__\n\nNeed to train your own Large Language Model? __Run inference at scale at a lower price point.__\n\nWant to personalize an LLM to your business, securely? __Fine tune open source models.__. Get started now"}, {"role": "assistant", "content": "https://app.endpoints.anyscale.com/"}]}
{"messages": [{"role": "user", "content": "__Slash costs__\nTrain and deploy your models at a fraction of the cost. Leverage the most recent advances from the open source community instantaneously. Transition to cheaper spot instances and run across multiple regions and multiple clouds. Autoscale rapidly to handle bursty workloads while minimizing steady-state costs. Scale CPU compute and GPU compute elastically and independently.\n\n__Extend your platform capabilities__\nLeverage the same LLM and generative AI capabilities previously only available to leaders like OpenAI and Uber, all in your cloud account. Develop interactively at scale. Bring models to production in hours instead of weeks. Enable multi-GPU and multi-node models with a single click.. Contact sales"}, {"role": "assistant", "content": "https://www.anyscale.com/signup"}]}
{"messages": [{"role": "user", "content": "Access Anyscale today to see how companies using Anyscale and Ray benefit from rapid time-to-market and faster iterations across the entire AI lifecycle.. Get started now"}, {"role": "assistant", "content": "https://www.anyscale.com/signup"}]}
{"messages": [{"role": "user", "content": "Anyscale Endpoints is a fast and scalable API to integrate OSS LLMs into your app. Get Started Now"}, {"role": "assistant", "content": "https://app.endpoints.anyscale.com/welcome"}]}
{"messages": [{"role": "user", "content": "Need to train your own Large Language Model? Run inference at scale at a lower price point.. Get Started Now"}, {"role": "assistant", "content": "https://app.endpoints.anyscale.com/welcome"}]}
{"messages": [{"role": "user", "content": "Effortlessly customize LLMs and run them in your Cloud or ours.. Sign Up for Fine-tuning Waitlist"}, {"role": "assistant", "content": "https://app.endpoints.anyscale.com/welcome"}]}
{"messages": [{"role": "user", "content": "- Fully serverless\n- Pay-as-you-go for $1 or less per million tokens\n- Easy to graduate to Enterprise\n. Get Started Now"}, {"role": "assistant", "content": "https://app.endpoints.anyscale.com/welcome"}]}
{"messages": [{"role": "user", "content": "- Runs in your Cloud\n- Pay for the compute you use. Contact Sales"}, {"role": "assistant", "content": "https://www.anyscale.com/signup"}]}
{"messages": [{"role": "user", "content": "Body content"}, {"role": "assistant", "content": "https://anyscale.com"}]}
